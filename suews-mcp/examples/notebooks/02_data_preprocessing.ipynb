{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for SUEWS Tutorial\n",
    "\n",
    "This notebook demonstrates how to preprocess meteorological data for SUEWS simulations using the MCP server.\n",
    "\n",
    "## What you'll learn:\n",
    "- How to assess raw meteorological data quality\n",
    "- How to convert between different data formats\n",
    "- How to validate energy balance data\n",
    "- How to handle missing data and gaps\n",
    "- How to prepare SUEWS-ready forcing files\n",
    "\n",
    "## Prerequisites:\n",
    "- SUEWS MCP server running\n",
    "- Sample meteorological data files (or synthetic data)\n",
    "- Python packages: `mcp`, `pandas`, `matplotlib`, `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import asyncio\n",
    "from mcp import create_client\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# For Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"üì¶ Packages imported successfully\")\n",
    "print(\"üîß Ready for data preprocessing workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Sample Data Files\n",
    "\n",
    "Since you might not have real meteorological data files, let's create some realistic sample data with various common issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_weather_data():\n",
    "    \"\"\"Create realistic sample meteorological data with some common issues.\"\"\"\n",
    "    \n",
    "    # Create directory for sample data\n",
    "    os.makedirs('sample_data', exist_ok=True)\n",
    "    \n",
    "    print(\"üèóÔ∏è Creating sample meteorological data files...\")\n",
    "    \n",
    "    # Generate hourly data for one month (July 2023)\n",
    "    start_date = datetime(2023, 7, 1)\n",
    "    end_date = datetime(2023, 7, 31, 23)\n",
    "    dates = pd.date_range(start_date, end_date, freq='H')\n",
    "    n_points = len(dates)\n",
    "    \n",
    "    # Generate realistic meteorological variables with daily patterns\n",
    "    hour_of_day = dates.hour\n",
    "    day_of_year = dates.dayofyear\n",
    "    \n",
    "    # Base patterns\n",
    "    temp_base = 20 + 8 * np.sin(2 * np.pi * (hour_of_day - 6) / 24)  # Diurnal temperature\n",
    "    temp_noise = np.random.normal(0, 2, n_points)  # Weather variability\n",
    "    temperature = temp_base + temp_noise\n",
    "    \n",
    "    # Relative humidity (inversely related to temperature)\n",
    "    rh_base = 70 - 20 * np.sin(2 * np.pi * (hour_of_day - 6) / 24)\n",
    "    humidity = np.clip(rh_base + np.random.normal(0, 10, n_points), 20, 95)\n",
    "    \n",
    "    # Wind speed (higher during day)\n",
    "    wind_base = 3 + 2 * np.sin(2 * np.pi * (hour_of_day - 10) / 24)\n",
    "    wind_speed = np.maximum(0.5, wind_base + np.random.normal(0, 1, n_points))\n",
    "    \n",
    "    # Wind direction (some variability)\n",
    "    wind_direction = 220 + 30 * np.sin(2 * np.pi * hour_of_day / 24) + np.random.normal(0, 20, n_points)\n",
    "    wind_direction = wind_direction % 360\n",
    "    \n",
    "    # Atmospheric pressure\n",
    "    pressure = 101.3 + np.random.normal(0, 2, n_points)\n",
    "    \n",
    "    # Solar radiation (zero at night, peak at noon)\n",
    "    solar_angle = np.maximum(0, np.sin(np.pi * (hour_of_day - 6) / 12))\n",
    "    solar_radiation = 800 * solar_angle * (0.7 + 0.3 * np.random.random(n_points))\n",
    "    \n",
    "    # Precipitation (random events)\n",
    "    rain_prob = np.random.random(n_points)\n",
    "    precipitation = np.where(rain_prob < 0.05, np.random.exponential(2, n_points), 0)\n",
    "    \n",
    "    # Energy fluxes (for flux tower data)\n",
    "    net_radiation = 0.7 * solar_radiation - 50  # Net radiation\n",
    "    sensible_heat = 0.3 * np.maximum(0, net_radiation) + np.random.normal(0, 15, n_points)\n",
    "    latent_heat = 0.4 * np.maximum(0, net_radiation) + np.random.normal(0, 20, n_points)\n",
    "    \n",
    "    # Create weather station CSV (with some issues)\n",
    "    weather_data = pd.DataFrame({\n",
    "        'timestamp': dates,\n",
    "        'air_temperature': temperature,\n",
    "        'relative_humidity': humidity,\n",
    "        'wind_speed': wind_speed,\n",
    "        'wind_direction': wind_direction,\n",
    "        'pressure': pressure,\n",
    "        'global_radiation': solar_radiation,\n",
    "        'precipitation': precipitation\n",
    "    })\n",
    "    \n",
    "    # Introduce some data quality issues\n",
    "    # 1. Missing data\n",
    "    missing_indices = np.random.choice(weather_data.index, size=20, replace=False)\n",
    "    weather_data.loc[missing_indices, 'relative_humidity'] = np.nan\n",
    "    \n",
    "    # 2. Some outliers\n",
    "    outlier_indices = np.random.choice(weather_data.index, size=5, replace=False)\n",
    "    weather_data.loc[outlier_indices, 'air_temperature'] = 45  # Unrealistic temperature\n",
    "    \n",
    "    # 3. Some negative radiation values (instrument error)\n",
    "    night_indices = weather_data[weather_data['global_radiation'] < 10].index\n",
    "    error_indices = np.random.choice(night_indices, size=10, replace=False)\n",
    "    weather_data.loc[error_indices, 'global_radiation'] = -20\n",
    "    \n",
    "    # Save weather station data\n",
    "    weather_data.to_csv('sample_data/weather_station.csv', index=False)\n",
    "    print(f\"‚úÖ Created weather_station.csv ({len(weather_data)} records)\")\n",
    "    \n",
    "    # Create flux tower data (Excel format)\n",
    "    flux_data = pd.DataFrame({\n",
    "        'TIMESTAMP': dates,\n",
    "        'TA_1_1_1': temperature,  # Air temperature\n",
    "        'RH_1_1_1': humidity,    # Relative humidity\n",
    "        'WS_1_1_1': wind_speed,  # Wind speed\n",
    "        'WD_1_1_1': wind_direction,  # Wind direction\n",
    "        'PA_1_1_1': pressure,    # Pressure\n",
    "        'SW_IN_1_1_1': solar_radiation,  # Shortwave in\n",
    "        'NETRAD_1_1_1': net_radiation,   # Net radiation\n",
    "        'H_1_1_1': sensible_heat,        # Sensible heat\n",
    "        'LE_1_1_1': latent_heat,         # Latent heat\n",
    "        'P_1_1_1': precipitation         # Precipitation\n",
    "    })\n",
    "    \n",
    "    # Introduce energy balance issues\n",
    "    # Some periods with poor closure\n",
    "    bad_closure_mask = np.random.random(n_points) < 0.1  # 10% of data\n",
    "    flux_data.loc[bad_closure_mask, 'H_1_1_1'] *= 1.5  # Overestimate sensible heat\n",
    "    \n",
    "    flux_data.to_excel('sample_data/flux_tower.xlsx', index=False)\n",
    "    print(f\"‚úÖ Created flux_tower.xlsx ({len(flux_data)} records)\")\n",
    "    \n",
    "    # Create text file with irregular time steps\n",
    "    irregular_dates = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        irregular_dates.append(current_date)\n",
    "        # Random time step between 30min and 2 hours\n",
    "        delta_minutes = np.random.randint(30, 120)\n",
    "        current_date += timedelta(minutes=delta_minutes)\n",
    "    \n",
    "    irregular_data = pd.DataFrame({\n",
    "        'datetime': irregular_dates[:500],  # Limit to 500 points\n",
    "        'Temperature': np.random.normal(20, 5, 500),\n",
    "        'Humidity': np.random.normal(60, 15, 500),\n",
    "        'WindSpeed': np.random.normal(3, 1, 500)\n",
    "    })\n",
    "    \n",
    "    irregular_data.to_csv('sample_data/irregular_timesteps.txt', sep='\\t', index=False)\n",
    "    print(f\"‚úÖ Created irregular_timesteps.txt ({len(irregular_data)} records)\")\n",
    "    \n",
    "    print(\"\\nüìÅ Sample data files created in 'sample_data/' directory\")\n",
    "    print(\"\\nüîç Data quality issues intentionally included:\")\n",
    "    print(\"   ‚Ä¢ Missing humidity values (weather station)\")\n",
    "    print(\"   ‚Ä¢ Temperature outliers (weather station)\")\n",
    "    print(\"   ‚Ä¢ Negative radiation values (weather station)\")\n",
    "    print(\"   ‚Ä¢ Poor energy balance closure (flux tower)\")\n",
    "    print(\"   ‚Ä¢ Irregular time steps (text file)\")\n",
    "\n",
    "# Create sample data\n",
    "create_sample_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to MCP Server\n",
    "\n",
    "Let's connect to the SUEWS MCP server and check that data preprocessing tools are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def check_preprocessing_tools():\n",
    "    \"\"\"Check that data preprocessing tools are available.\"\"\"\n",
    "    try:\n",
    "        async with create_client(\"suews-mcp\") as client:\n",
    "            print(\"‚úÖ Connected to SUEWS MCP server\")\n",
    "            \n",
    "            # List tools and check for preprocessing capabilities\n",
    "            tools = await client.list_tools()\n",
    "            \n",
    "            preprocessing_tools = [\n",
    "                'preprocess_forcing',\n",
    "                'convert_data_format',\n",
    "                'validate_config'\n",
    "            ]\n",
    "            \n",
    "            available_tools = [tool.name for tool in tools.tools]\n",
    "            \n",
    "            print(\"\\nüîß Data preprocessing tools:\")\n",
    "            for tool_name in preprocessing_tools:\n",
    "                if tool_name in available_tools:\n",
    "                    print(f\"   ‚úÖ {tool_name}\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå {tool_name} (not available)\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check connection and tools\n",
    "connection_ok = await check_preprocessing_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assess Raw Data Quality\n",
    "\n",
    "Let's use the preprocessing tool to assess the quality of our sample weather station data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def assess_weather_station_data():\n",
    "    \"\"\"Assess quality of weather station data.\"\"\"\n",
    "    if not connection_ok:\n",
    "        print(\"‚ùå Skipping - no MCP connection\")\n",
    "        return\n",
    "    \n",
    "    async with create_client(\"suews-mcp\") as client:\n",
    "        print(\"üîç Assessing weather station data quality...\")\n",
    "        \n",
    "        try:\n",
    "            # First, let's try to preprocess without fixing issues\n",
    "            assessment = await client.call_tool(\"preprocess_forcing\", {\n",
    "                \"input_file\": \"sample_data/weather_station.csv\",\n",
    "                \"output_file\": \"sample_data/weather_station_assessed.txt\",\n",
    "                \"validate_energy_balance\": False,  # No energy balance data\n",
    "                \"auto_fix_issues\": False,  # Just assess first\n",
    "                \"target_timestep\": 3600  # Hourly\n",
    "            })\n",
    "            \n",
    "            print(\"üìä Data Quality Assessment:\")\n",
    "            print(\"=\" * 50)\n",
    "            print(assessment.content[0].text)\n",
    "            \n",
    "            return assessment\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Assessment failed: {e}\")\n",
    "            print(\"This might be due to file format issues or missing MCP tools\")\n",
    "            return None\n",
    "\n",
    "# Assess data quality\n",
    "if connection_ok:\n",
    "    assessment_result = await assess_weather_station_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert Data Formats\n",
    "\n",
    "Let's convert the Excel flux tower data to SUEWS format, demonstrating column mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_flux_tower_data():\n",
    "    \"\"\"Convert flux tower Excel data to SUEWS format.\"\"\"\n",
    "    if not connection_ok:\n",
    "        print(\"‚ùå Skipping - no MCP connection\")\n",
    "        return\n",
    "    \n",
    "    async with create_client(\"suews-mcp\") as client:\n",
    "        print(\"üîÑ Converting flux tower data format...\")\n",
    "        \n",
    "        try:\n",
    "            conversion = await client.call_tool(\"convert_data_format\", {\n",
    "                \"input_file\": \"sample_data/flux_tower.xlsx\",\n",
    "                \"output_file\": \"sample_data/flux_tower_suews.txt\",\n",
    "                \"input_format\": \"excel\",\n",
    "                \"output_format\": \"suews_txt\",\n",
    "                \"column_mapping\": {\n",
    "                    \"TIMESTAMP\": \"datetime\",\n",
    "                    \"TA_1_1_1\": \"Tair\",         # Air temperature\n",
    "                    \"RH_1_1_1\": \"RH\",           # Relative humidity\n",
    "                    \"WS_1_1_1\": \"U\",            # Wind speed\n",
    "                    \"WD_1_1_1\": \"WDir\",         # Wind direction\n",
    "                    \"PA_1_1_1\": \"Pres\",         # Pressure\n",
    "                    \"SW_IN_1_1_1\": \"Kdown\",     # Shortwave incoming\n",
    "                    \"NETRAD_1_1_1\": \"QN\",       # Net radiation\n",
    "                    \"H_1_1_1\": \"QH\",            # Sensible heat flux\n",
    "                    \"LE_1_1_1\": \"QE\",           # Latent heat flux\n",
    "                    \"P_1_1_1\": \"Rain\"           # Precipitation\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            print(\"üìÑ Format Conversion Results:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(conversion.content[0].text)\n",
    "            \n",
    "            return conversion\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Conversion failed: {e}\")\n",
    "            print(\"This might be due to file format issues or missing dependencies\")\n",
    "            return None\n",
    "\n",
    "# Convert flux tower data\n",
    "if connection_ok:\n",
    "    conversion_result = await convert_flux_tower_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Energy Balance Validation\n",
    "\n",
    "Now let's validate the energy balance in the converted flux tower data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_energy_balance():\n",
    "    \"\"\"Validate energy balance in flux tower data.\"\"\"\n",
    "    if not connection_ok:\n",
    "        print(\"‚ùå Skipping - no MCP connection\")\n",
    "        return\n",
    "    \n",
    "    async with create_client(\"suews-mcp\") as client:\n",
    "        print(\"‚öñÔ∏è Validating energy balance...\")\n",
    "        \n",
    "        try:\n",
    "            validation = await client.call_tool(\"preprocess_forcing\", {\n",
    "                \"input_file\": \"sample_data/flux_tower_suews.txt\",\n",
    "                \"output_file\": \"sample_data/flux_tower_validated.txt\",\n",
    "                \"validate_energy_balance\": True,  # Check QN = QH + QE + QS\n",
    "                \"auto_fix_issues\": False,  # Just validate first\n",
    "                \"target_timestep\": 3600\n",
    "            })\n",
    "            \n",
    "            print(\"‚öñÔ∏è Energy Balance Validation Results:\")\n",
    "            print(\"=\" * 45)\n",
    "            print(validation.content[0].text)\n",
    "            \n",
    "            return validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Energy balance validation failed: {e}\")\n",
    "            print(\"This might be because the converted file doesn't exist or has format issues\")\n",
    "            return None\n",
    "\n",
    "# Validate energy balance\n",
    "if connection_ok:\n",
    "    energy_validation = await validate_energy_balance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fix Data Issues\n",
    "\n",
    "Let's now apply automatic fixes to the weather station data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fix_weather_station_issues():\n",
    "    \"\"\"Apply automatic fixes to weather station data.\"\"\"\n",
    "    if not connection_ok:\n",
    "        print(\"‚ùå Skipping - no MCP connection\")\n",
    "        return\n",
    "    \n",
    "    async with create_client(\"suews-mcp\") as client:\n",
    "        print(\"üîß Applying automatic fixes to weather station data...\")\n",
    "        \n",
    "        try:\n",
    "            fixing = await client.call_tool(\"preprocess_forcing\", {\n",
    "                \"input_file\": \"sample_data/weather_station.csv\",\n",
    "                \"output_file\": \"sample_data/weather_station_fixed.txt\",\n",
    "                \"validate_energy_balance\": False,\n",
    "                \"auto_fix_issues\": True,  # Now apply fixes\n",
    "                \"target_timestep\": 3600\n",
    "            })\n",
    "            \n",
    "            print(\"üõ†Ô∏è Data Fixing Results:\")\n",
    "            print(\"=\" * 30)\n",
    "            print(fixing.content[0].text)\n",
    "            \n",
    "            return fixing\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Data fixing failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# Fix data issues\n",
    "if connection_ok:\n",
    "    fixing_result = await fix_weather_station_issues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare Before and After\n",
    "\n",
    "Let's load the original and processed data to see what changes were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_before_after():\n",
    "    \"\"\"Compare original and processed data to show improvements.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load original data\n",
    "        original_data = pd.read_csv('sample_data/weather_station.csv', parse_dates=['timestamp'])\n",
    "        print(\"‚úÖ Loaded original weather station data\")\n",
    "        \n",
    "        # Try to load processed data\n",
    "        processed_files = [\n",
    "            'sample_data/weather_station_fixed.txt',\n",
    "            'sample_data/weather_station_assessed.txt'\n",
    "        ]\n",
    "        \n",
    "        processed_data = None\n",
    "        for file_path in processed_files:\n",
    "            try:\n",
    "                processed_data = pd.read_csv(file_path, delim_whitespace=True)\n",
    "                print(f\"‚úÖ Loaded processed data from {file_path}\")\n",
    "                break\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        \n",
    "        if processed_data is None:\n",
    "            print(\"‚ö†Ô∏è No processed data file found, creating comparison with original data only\")\n",
    "            processed_data = original_data.copy()\n",
    "        \n",
    "        # Create comparison plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Data Preprocessing Comparison: Before vs After', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Temperature comparison\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(original_data['timestamp'], original_data['air_temperature'], \n",
    "                'b-', alpha=0.7, label='Original', linewidth=1)\n",
    "        \n",
    "        if 'Tair' in processed_data.columns:\n",
    "            ax1.plot(original_data['timestamp'], processed_data['Tair'], \n",
    "                    'r-', alpha=0.8, label='Processed', linewidth=1.5)\n",
    "        \n",
    "        ax1.set_title('Air Temperature Comparison', fontweight='bold')\n",
    "        ax1.set_ylabel('Temperature (¬∞C)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight outliers in original data\n",
    "        outliers = original_data['air_temperature'] > 35\n",
    "        if outliers.any():\n",
    "            ax1.scatter(original_data.loc[outliers, 'timestamp'], \n",
    "                       original_data.loc[outliers, 'air_temperature'],\n",
    "                       color='red', s=50, marker='x', label='Outliers', zorder=5)\n",
    "        \n",
    "        # Plot 2: Humidity with missing data\n",
    "        ax2 = axes[0, 1]\n",
    "        ax2.plot(original_data['timestamp'], original_data['relative_humidity'], \n",
    "                'b-', alpha=0.7, label='Original (with gaps)', linewidth=1)\n",
    "        \n",
    "        if 'RH' in processed_data.columns:\n",
    "            ax2.plot(original_data['timestamp'], processed_data['RH'], \n",
    "                    'g-', alpha=0.8, label='Gap-filled', linewidth=1.5)\n",
    "        \n",
    "        ax2.set_title('Relative Humidity (Gap Filling)', fontweight='bold')\n",
    "        ax2.set_ylabel('Relative Humidity (%)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Solar radiation (fixing negative values)\n",
    "        ax3 = axes[1, 0]\n",
    "        ax3.plot(original_data['timestamp'], original_data['global_radiation'], \n",
    "                'b-', alpha=0.7, label='Original', linewidth=1)\n",
    "        \n",
    "        if 'Kdown' in processed_data.columns:\n",
    "            ax3.plot(original_data['timestamp'], processed_data['Kdown'], \n",
    "                    'orange', alpha=0.8, label='Corrected', linewidth=1.5)\n",
    "        \n",
    "        ax3.set_title('Solar Radiation (Negative Value Correction)', fontweight='bold')\n",
    "        ax3.set_ylabel('Solar Radiation (W/m¬≤)')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.axhline(0, color='red', linestyle='--', alpha=0.5, label='Zero line')\n",
    "        \n",
    "        # Highlight negative values\n",
    "        negative_mask = original_data['global_radiation'] < 0\n",
    "        if negative_mask.any():\n",
    "            ax3.scatter(original_data.loc[negative_mask, 'timestamp'],\n",
    "                       original_data.loc[negative_mask, 'global_radiation'],\n",
    "                       color='red', s=30, marker='v', label='Negative values')\n",
    "        \n",
    "        # Plot 4: Data completeness comparison\n",
    "        ax4 = axes[1, 1]\n",
    "        \n",
    "        # Calculate completeness for key variables\n",
    "        original_completeness = {\n",
    "            'Temperature': (1 - original_data['air_temperature'].isna().mean()) * 100,\n",
    "            'Humidity': (1 - original_data['relative_humidity'].isna().mean()) * 100,\n",
    "            'Wind': (1 - original_data['wind_speed'].isna().mean()) * 100,\n",
    "            'Radiation': (1 - original_data['global_radiation'].isna().mean()) * 100\n",
    "        }\n",
    "        \n",
    "        if len(processed_data.columns) > 4:  # Has processed data\n",
    "            var_mapping = {'air_temperature': 'Tair', 'relative_humidity': 'RH', \n",
    "                          'wind_speed': 'U', 'global_radiation': 'Kdown'}\n",
    "            processed_completeness = {}\n",
    "            for orig_var, proc_var in var_mapping.items():\n",
    "                if proc_var in processed_data.columns:\n",
    "                    processed_completeness[orig_var.replace('_', ' ').title()] = (\n",
    "                        1 - processed_data[proc_var].isna().mean()) * 100\n",
    "        else:\n",
    "            processed_completeness = original_completeness.copy()\n",
    "        \n",
    "        variables = list(original_completeness.keys())\n",
    "        orig_values = list(original_completeness.values())\n",
    "        proc_values = [processed_completeness.get(var, orig_values[i]) \n",
    "                      for i, var in enumerate(variables)]\n",
    "        \n",
    "        x = np.arange(len(variables))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax4.bar(x - width/2, orig_values, width, label='Original', alpha=0.7, color='lightblue')\n",
    "        bars2 = ax4.bar(x + width/2, proc_values, width, label='Processed', alpha=0.7, color='lightgreen')\n",
    "        \n",
    "        ax4.set_title('Data Completeness Comparison', fontweight='bold')\n",
    "        ax4.set_ylabel('Completeness (%)')\n",
    "        ax4.set_xticks(x)\n",
    "        ax4.set_xticklabels(variables, rotation=45, ha='right')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        ax4.set_ylim(0, 105)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars1, orig_values):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                    f'{value:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        for bar, value in zip(bars2, proc_values):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                    f'{value:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nüìä Data Quality Summary:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        print(f\"üìà Original data points: {len(original_data):,}\")\n",
    "        print(f\"üìà Missing humidity values: {original_data['relative_humidity'].isna().sum()}\")\n",
    "        print(f\"üå°Ô∏è Temperature outliers (>35¬∞C): {(original_data['air_temperature'] > 35).sum()}\")\n",
    "        print(f\"‚òÄÔ∏è Negative radiation values: {(original_data['global_radiation'] < 0).sum()}\")\n",
    "        \n",
    "        if len(processed_data.columns) > 4:\n",
    "            print(f\"\\n‚úÖ After processing:\")\n",
    "            print(f\"üìà Processed data points: {len(processed_data):,}\")\n",
    "            if 'RH' in processed_data.columns:\n",
    "                print(f\"üìà Missing humidity values: {processed_data['RH'].isna().sum()}\")\n",
    "            if 'Kdown' in processed_data.columns:\n",
    "                print(f\"‚òÄÔ∏è Negative radiation values: {(processed_data['Kdown'] < 0).sum()}\")\n",
    "        \n",
    "        return original_data, processed_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Comparison failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Compare before and after\n",
    "original_data, processed_data = compare_before_after()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Final SUEWS-Ready Dataset\n",
    "\n",
    "Let's demonstrate how to create a final dataset that's ready for SUEWS simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_suews_ready_dataset():\n",
    "    \"\"\"Create a final SUEWS-ready dataset from processed data.\"\"\"\n",
    "    \n",
    "    print(\"üéØ Creating final SUEWS-ready dataset...\")\n",
    "    \n",
    "    # Check if we have processed data, otherwise use original\n",
    "    data_files = [\n",
    "        'sample_data/weather_station_fixed.txt',\n",
    "        'sample_data/weather_station_assessed.txt'\n",
    "    ]\n",
    "    \n",
    "    processed_df = None\n",
    "    for file_path in data_files:\n",
    "        try:\n",
    "            processed_df = pd.read_csv(file_path, delim_whitespace=True)\n",
    "            print(f\"‚úÖ Using processed data from: {file_path}\")\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    \n",
    "    if processed_df is None:\n",
    "        print(\"‚ö†Ô∏è No processed data found, creating from original data...\")\n",
    "        original_df = pd.read_csv('sample_data/weather_station.csv')\n",
    "        \n",
    "        # Create SUEWS format manually\n",
    "        processed_df = pd.DataFrame({\n",
    "            'Year': 2023,\n",
    "            'DOY': pd.to_datetime(original_df['timestamp']).dt.dayofyear,\n",
    "            'Hour': pd.to_datetime(original_df['timestamp']).dt.hour,\n",
    "            'Min': 0,\n",
    "            'Tair': original_df['air_temperature'].fillna(method='linear'),\n",
    "            'RH': original_df['relative_humidity'].fillna(method='linear'),\n",
    "            'U': original_df['wind_speed'],\n",
    "            'WDir': original_df['wind_direction'],\n",
    "            'Pres': original_df['pressure'],\n",
    "            'Kdown': np.maximum(0, original_df['global_radiation']),  # Fix negative values\n",
    "            'Rain': original_df['precipitation']\n",
    "        })\n",
    "    \n",
    "    # Ensure all required SUEWS variables are present\n",
    "    required_vars = ['Year', 'DOY', 'Hour', 'Min', 'Tair', 'RH', 'U', 'Pres', 'Kdown', 'Rain']\n",
    "    missing_vars = [var for var in required_vars if var not in processed_df.columns]\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"‚ö†Ô∏è Missing required variables: {missing_vars}\")\n",
    "        print(\"Available variables:\", list(processed_df.columns))\n",
    "        \n",
    "        # Add missing time variables if needed\n",
    "        if 'Year' not in processed_df.columns:\n",
    "            processed_df['Year'] = 2023\n",
    "        if 'DOY' not in processed_df.columns:\n",
    "            processed_df['DOY'] = 182 + np.arange(len(processed_df)) // 24  # Start from July 1st\n",
    "        if 'Hour' not in processed_df.columns:\n",
    "            processed_df['Hour'] = np.arange(len(processed_df)) % 24\n",
    "        if 'Min' not in processed_df.columns:\n",
    "            processed_df['Min'] = 0\n",
    "    \n",
    "    # Reorder columns to match SUEWS format\n",
    "    suews_columns = ['Year', 'DOY', 'Hour', 'Min', 'Tair', 'RH', 'U', 'WDir', 'Pres', 'Kdown', 'Rain']\n",
    "    available_columns = [col for col in suews_columns if col in processed_df.columns]\n",
    "    \n",
    "    final_df = processed_df[available_columns].copy()\n",
    "    \n",
    "    # Data quality checks\n",
    "    print(\"\\nüîç Final dataset quality checks:\")\n",
    "    \n",
    "    for var in ['Tair', 'RH', 'U', 'Kdown']:\n",
    "        if var in final_df.columns:\n",
    "            missing_pct = (final_df[var].isna().mean()) * 100\n",
    "            if missing_pct < 5:\n",
    "                status = \"‚úÖ\"\n",
    "            elif missing_pct < 20:\n",
    "                status = \"‚ö†Ô∏è\"\n",
    "            else:\n",
    "                status = \"‚ùå\"\n",
    "            print(f\"   {status} {var}: {missing_pct:.1f}% missing\")\n",
    "    \n",
    "    # Check value ranges\n",
    "    range_checks = {\n",
    "        'Tair': (-30, 50),\n",
    "        'RH': (0, 100),\n",
    "        'U': (0, 30),\n",
    "        'Kdown': (0, 1200)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüå°Ô∏è Value range checks:\")\n",
    "    for var, (min_val, max_val) in range_checks.items():\n",
    "        if var in final_df.columns:\n",
    "            out_of_range = ((final_df[var] < min_val) | (final_df[var] > max_val)).sum()\n",
    "            if out_of_range == 0:\n",
    "                status = \"‚úÖ\"\n",
    "            elif out_of_range < len(final_df) * 0.01:  # <1%\n",
    "                status = \"‚ö†Ô∏è\"\n",
    "            else:\n",
    "                status = \"‚ùå\"\n",
    "            print(f\"   {status} {var}: {out_of_range} values outside range [{min_val}, {max_val}]\")\n",
    "    \n",
    "    # Save final dataset\n",
    "    output_file = 'sample_data/final_suews_forcing.txt'\n",
    "    final_df.to_csv(output_file, sep=' ', index=False, float_format='%.3f')\n",
    "    \n",
    "    print(f\"\\nüíæ Final SUEWS-ready dataset saved: {output_file}\")\n",
    "    print(f\"üìä Dataset shape: {final_df.shape}\")\n",
    "    print(f\"üìÖ Time period: {final_df.shape[0]} hours\")\n",
    "    print(f\"üóÇÔ∏è Variables: {', '.join(final_df.columns)}\")\n",
    "    \n",
    "    # Show sample of final data\n",
    "    print(\"\\nüìã Sample of final dataset:\")\n",
    "    print(final_df.head(10).round(3))\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Create final dataset\n",
    "final_dataset = create_suews_ready_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Validate Final Dataset\n",
    "\n",
    "Let's validate our final dataset against SUEWS requirements using the MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_final_dataset():\n",
    "    \"\"\"Validate the final SUEWS-ready dataset.\"\"\"\n",
    "    if not connection_ok:\n",
    "        print(\"‚ùå Skipping - no MCP connection\")\n",
    "        return\n",
    "    \n",
    "    async with create_client(\"suews-mcp\") as client:\n",
    "        print(\"üîç Final validation of SUEWS-ready dataset...\")\n",
    "        \n",
    "        try:\n",
    "            validation = await client.call_tool(\"preprocess_forcing\", {\n",
    "                \"input_file\": \"sample_data/final_suews_forcing.txt\",\n",
    "                \"validate_energy_balance\": False,  # No energy balance in weather station data\n",
    "                \"auto_fix_issues\": False,  # Just validate\n",
    "                \"target_timestep\": 3600\n",
    "            })\n",
    "            \n",
    "            print(\"‚úÖ Final Dataset Validation:\")\n",
    "            print(\"=\" * 35)\n",
    "            print(validation.content[0].text)\n",
    "            \n",
    "            # Check if validation indicates readiness for SUEWS\n",
    "            validation_text = validation.content[0].text.upper()\n",
    "            if \"SUCCESS\" in validation_text and \"READY\" in validation_text:\n",
    "                print(\"\\nüéâ Dataset is ready for SUEWS simulation!\")\n",
    "            elif \"SUCCESS\" in validation_text:\n",
    "                print(\"\\n‚úÖ Dataset validation passed. Minor issues may exist but simulation should work.\")\n",
    "            else:\n",
    "                print(\"\\n‚ö†Ô∏è Dataset has issues that should be addressed before simulation.\")\n",
    "            \n",
    "            return validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Final validation failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# Validate final dataset\n",
    "if connection_ok and final_dataset is not None:\n",
    "    final_validation = await validate_final_dataset()\n",
    "elif final_dataset is not None:\n",
    "    print(\"üìä Manual validation of final dataset:\")\n",
    "    print(f\"   ‚úÖ Dataset shape: {final_dataset.shape}\")\n",
    "    print(f\"   ‚úÖ Required time variables present: Year, DOY, Hour, Min\")\n",
    "    print(f\"   ‚úÖ Required meteorological variables: {', '.join(['Tair', 'RH', 'U', 'Kdown', 'Rain'])}\")\n",
    "    print(f\"   ‚úÖ Dataset appears ready for SUEWS simulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "Congratulations! You've completed a comprehensive data preprocessing workflow for SUEWS. Here's what you accomplished:\n",
    "\n",
    "### ‚úÖ What you did:\n",
    "1. **Created sample data** with realistic meteorological variables and common issues\n",
    "2. **Assessed data quality** using MCP preprocessing tools\n",
    "3. **Converted data formats** from Excel to SUEWS format with column mapping\n",
    "4. **Validated energy balance** for flux tower data\n",
    "5. **Applied automatic fixes** to common data issues\n",
    "6. **Created final SUEWS-ready** forcing file\n",
    "7. **Visualized improvements** in data quality\n",
    "\n",
    "### üìä Key Data Quality Issues Addressed:\n",
    "- **Missing data**: Gap-filled humidity measurements\n",
    "- **Outliers**: Removed unrealistic temperature spikes  \n",
    "- **Negative values**: Fixed negative solar radiation measurements\n",
    "- **Energy balance**: Validated flux tower energy closure\n",
    "- **Format conversion**: Standardized column names and units\n",
    "- **Temporal consistency**: Ensured regular time steps\n",
    "\n",
    "### üöÄ Best Practices for Real Data:\n",
    "\n",
    "#### 1. Data Source Hierarchy\n",
    "```python\n",
    "# Priority order for merging multiple datasets:\n",
    "# 1. High-quality flux tower measurements\n",
    "# 2. Standard weather station data  \n",
    "# 3. Reanalysis/gridded data for gap filling\n",
    "```\n",
    "\n",
    "#### 2. Quality Control Thresholds\n",
    "- **Temperature**: -50¬∞C to +60¬∞C (climate dependent)\n",
    "- **Humidity**: 0% to 100%\n",
    "- **Wind speed**: 0 to 50 m/s (>30 m/s rare)\n",
    "- **Solar radiation**: 0 to 1400 W/m¬≤\n",
    "- **Energy balance closure**: 80-120% acceptable\n",
    "\n",
    "#### 3. Missing Data Handling\n",
    "- **<5% missing**: Linear interpolation acceptable\n",
    "- **5-20% missing**: Use climatological patterns\n",
    "- **>20% missing**: Find alternative data sources\n",
    "\n",
    "#### 4. Energy Balance Requirements\n",
    "For flux tower data: **QN = QH + QE + QS ¬± residual**\n",
    "- Residual should be <20% of QN\n",
    "- Bowen ratio (QH/QE) should be 0.1-5.0 for most urban areas\n",
    "\n",
    "### üîß Common Data Issues and Solutions:\n",
    "\n",
    "| Issue | Symptoms | Solution |\n",
    "|-------|----------|----------|\n",
    "| **Clock errors** | Time jumps, irregular intervals | Use `target_timestep` parameter |\n",
    "| **Unit mismatches** | Unrealistic values | Check units in column mapping |\n",
    "| **Instrument drift** | Gradual bias over time | Use reference data for correction |\n",
    "| **Sensor failures** | Long periods of constant values | Flag and interpolate |\n",
    "| **Format issues** | Parsing errors | Use appropriate `input_format` |\n",
    "\n",
    "### üìà Next Steps:\n",
    "\n",
    "1. **Use Your Own Data**:\n",
    "   ```python\n",
    "   # Process your meteorological data\n",
    "   await client.call_tool(\"preprocess_forcing\", {\n",
    "       \"input_file\": \"your_data.csv\",\n",
    "       \"auto_fix_issues\": True,\n",
    "       \"validate_energy_balance\": True\n",
    "   })\n",
    "   ```\n",
    "\n",
    "2. **Run SUEWS Simulation**:\n",
    "   ```python\n",
    "   # Use your processed data in simulation\n",
    "   await client.call_tool(\"run_simulation\", {\n",
    "       \"forcing_path\": \"sample_data/final_suews_forcing.txt\",\n",
    "       \"config_path\": \"residential_config.yml\"\n",
    "   })\n",
    "   ```\n",
    "\n",
    "3. **Advanced Preprocessing**:\n",
    "   - Multi-source data merging\n",
    "   - Quality control with observations\n",
    "   - Long-term trend analysis\n",
    "   - Climate change scenario preparation\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- [SUEWS MCP API Reference](../docs/api_reference.md)\n",
    "- [Data Preprocessing Workflow Guide](../docs/examples/data_preprocessing_workflow.md)\n",
    "- [Urban Heat Island Example](../docs/examples/urban_heat_island_study.md)\n",
    "- [FAQ & Troubleshooting](../docs/faq.md)\n",
    "\n",
    "### üÜò Need Help?\n",
    "- Check the [FAQ & Troubleshooting Guide](../docs/faq.md)\n",
    "- Visit [SUEWS Documentation](https://suews.readthedocs.io/)\n",
    "- Open an issue on [GitHub](https://github.com/UMEP-dev/SUEWS/issues)\n",
    "\n",
    "Your data is now ready for urban climate modeling! üìäüèôÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéâ DATA PREPROCESSING TUTORIAL COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if connection_ok:\n",
    "    print(\"‚úÖ MCP server connection: SUCCESS\")\n",
    "else:\n",
    "    print(\"‚ùå MCP server connection: FAILED\")\n",
    "\n",
    "if final_dataset is not None:\n",
    "    print(\"‚úÖ Sample data creation: SUCCESS\")\n",
    "    print(\"‚úÖ Data preprocessing: COMPLETED\")\n",
    "    print(f\"üìä Final dataset: {final_dataset.shape[0]:,} data points\")\n",
    "    print(f\"üóÇÔ∏è Variables: {len(final_dataset.columns)}\")\n",
    "    print(\"üíæ Output: sample_data/final_suews_forcing.txt\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Data preprocessing: INCOMPLETE\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to run SUEWS simulations with your processed data!\")\n",
    "print(\"\\nüìñ Next: Try the Basic Simulation notebook with your processed forcing data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}