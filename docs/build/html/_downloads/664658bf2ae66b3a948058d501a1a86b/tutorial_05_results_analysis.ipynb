{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Analysing Simulation Results\n\nComprehensive analysis and validation of SUEWS outputs.\n\nUnderstanding and analysing SUEWS output is essential for scientific\ninterpretation and model validation. This tutorial covers:\n\n1. **Output structure** - Navigating the results DataFrame\n2. **Statistical analysis** - Energy and water balance calculations\n3. **Diagnostic plots** - Visualising model behaviour\n4. **Validation** - Comparing with observations\n5. **Export** - Saving results for further use\n\n**Prerequisites**: Complete :doc:`tutorial_01_quick_start` first.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\nfrom supy import SUEWSSimulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Run Simulation\n\nFirst, run a simulation to generate results for analysis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sim = SUEWSSimulation.from_sample_data()\noutput = sim.run()\n\nprint(\"Simulation complete!\")\nprint(f\"Output period: {output.times[0]} to {output.times[-1]}\")\nprint(f\"Time steps: {len(output.times)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Output Structure\n\nSUEWS results use MultiIndex columns organised by output groups:\n\n- **SUEWS**: Primary energy and water balance (QN, QH, QE, QS, QF, etc.)\n- **DailyState**: Daily summary variables (LAI, GDD, snow density)\n- **snow**: Detailed snow variables by surface type\n- **RSL**: Roughness sublayer profiles\n\nAccess variables using ``get_variable()`` or direct MultiIndex indexing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = output.df\n\n# Method 1: get_variable() on output object - recommended\nqh = output.get_variable(\"QH\", group=\"SUEWS\")\nprint(f\"QH shape: {qh.shape}\")\n\n# Method 2: Direct MultiIndex access on raw DataFrame\nqn = results[(\"SUEWS\", \"QN\")]\nprint(f\"QN shape: {qn.shape}\")\n\n# List available groups and variables\nprint(f\"\\nAvailable groups: {output.groups}\")\nprint(f\"SUEWS variables (first 10): {results['SUEWS'].columns.tolist()[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Function for Variable Access\n\nCreate a helper to simplify extracting multiple variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_var(out, name, group=\"SUEWS\"):\n    \"\"\"Extract a single variable as a Series with DatetimeIndex.\n\n    Assumes single-grid output (as produced by the sample data).\n    Raises an error if multiple grids are present, since dropping\n    the grid level would produce a non-unique index.\n    \"\"\"\n    ser = out.get_variable(name, group=group).iloc[:, 0]\n    # Drop grid level only when safe (single grid)\n    if isinstance(ser.index, pd.MultiIndex) and ser.index.nlevels == 2:\n        n_grids = ser.index.get_level_values(\"grid\").nunique()\n        if n_grids != 1:\n            raise ValueError(\n                f\"Expected single-grid output, but found {n_grids} grids. \"\n                \"Use MultiIndex indexing directly for multi-grid runs.\"\n            )\n        ser = ser.droplevel(\"grid\")\n    return ser\n\n\ndef get_vars(out, names, group=\"SUEWS\"):\n    \"\"\"Extract multiple variables as a DataFrame with DatetimeIndex.\"\"\"\n    return pd.DataFrame({name: get_var(out, name, group) for name in names})\n\n\n# Extract energy balance components\nenergy_vars = [\"QN\", \"QF\", \"QS\", \"QE\", \"QH\"]\nenergy_df = get_vars(output, energy_vars)\n\nprint(\"Energy balance components:\")\nprint(energy_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Statistics\n\nCalculate summary statistics for the energy balance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Annual Energy Balance Statistics (W/m2):\")\nprint(energy_df.describe().round(1))\n\n# Seasonal means using meteorological seasons (month-based grouping)\nseason_map = {12: \"Winter (DJF)\", 1: \"Winter (DJF)\", 2: \"Winter (DJF)\",\n              3: \"Spring (MAM)\", 4: \"Spring (MAM)\", 5: \"Spring (MAM)\",\n              6: \"Summer (JJA)\", 7: \"Summer (JJA)\", 8: \"Summer (JJA)\",\n              9: \"Autumn (SON)\", 10: \"Autumn (SON)\", 11: \"Autumn (SON)\"}\nseason_order = [\"Winter (DJF)\", \"Spring (MAM)\", \"Summer (JJA)\", \"Autumn (SON)\"]\nseasonal = energy_df.groupby(energy_df.index.month.map(season_map)).mean()\nseasonal = seasonal.loc[season_order]\nprint(\"\\nSeasonal Means (W/m2):\")\nprint(seasonal.round(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Energy Balance Closure\n\nVerify that the energy balance closes: QN + QF = QS + QE + QH\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_in = get_var(output, \"QN\") + get_var(output, \"QF\")\nenergy_out = get_var(output, \"QS\") + get_var(output, \"QE\") + get_var(output, \"QH\")\nresidual = energy_in - energy_out\n\nprint(\"Energy Balance Closure Check:\")\nprint(f\"  Mean residual: {residual.mean():.4f} W/m2\")\nprint(f\"  Std residual:  {residual.std():.4f} W/m2\")\nprint(f\"  Max |residual|: {residual.abs().max():.4f} W/m2\")\nprint(\"\\nNote: SUEWS enforces closure by design. Non-zero residuals\")\nprint(\"indicate numerical precision limits only.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Water Balance Analysis\n\nCalculate annual water balance: P + I = E + R + D + dS\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rain = get_var(output, \"Rain\")\nevap = get_var(output, \"Evap\")\nrunoff = get_var(output, \"RO\")\ndrainage = get_var(output, \"Drainage\")\nirr = get_var(output, \"Irr\")\nstorage_change = get_var(output, \"TotCh\")\n\n# Annual totals (mm/year)\nprint(\"Annual Water Balance (mm):\")\nprint(\"  Inputs:\")\nprint(f\"    Precipitation: {rain.sum():.1f}\")\nprint(f\"    Irrigation:    {irr.sum():.1f}\")\nprint(\"  Outputs:\")\nprint(f\"    Evaporation:   {evap.sum():.1f}\")\nprint(f\"    Runoff:        {runoff.sum():.1f}\")\nprint(f\"    Drainage:      {drainage.sum():.1f}\")\nprint(f\"  Storage change:  {storage_change.sum():.1f}\")\n\nwater_residual = (rain.sum() + irr.sum()) - evap.sum() - runoff.sum() - drainage.sum() - storage_change.sum()\nprint(f\"  Residual:        {water_residual:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Energy Balance Time Series\n\nVisualise energy fluxes over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Daily energy fluxes\nax = axes[0, 0]\ndaily_energy = energy_df.resample(\"D\").mean()\ndaily_energy.plot(ax=ax)\nax.set_ylabel(\"Energy Flux (W/m2)\")\nax.set_title(\"Daily Mean Energy Fluxes\")\nax.legend(loc=\"upper right\")\nax.axhline(y=0, color=\"k\", linestyle=\"--\", alpha=0.3)\n\n# 2. Monthly energy partitioning\nax = axes[0, 1]\nmonthly_means = energy_df[[\"QS\", \"QE\", \"QH\"]].groupby(energy_df.index.month).mean()\nmonthly_means.plot(kind=\"bar\", ax=ax)\nax.set_xlabel(\"Month\")\nax.set_ylabel(\"Energy Flux (W/m2)\")\nax.set_title(\"Monthly Energy Partitioning\")\nax.legend(loc=\"upper right\")\n\n# 3. Summer diurnal cycle\nax = axes[1, 0]\nsummer_mask = energy_df.index.month.isin([6, 7, 8])\nsummer_energy = energy_df[summer_mask]\nhourly_summer = summer_energy.groupby(summer_energy.index.hour).mean()\nhourly_summer.plot(ax=ax, marker=\"o\", markersize=3)\nax.set_xlabel(\"Hour of Day\")\nax.set_ylabel(\"Energy Flux (W/m2)\")\nax.set_title(\"Summer Diurnal Cycle\")\nax.legend(loc=\"upper right\")\nax.axhline(y=0, color=\"k\", linestyle=\"--\", alpha=0.3)\n\n# 4. Bowen ratio (QH/QE) over time\nax = axes[1, 1]\nbowen = get_var(output, \"QH\") / get_var(output, \"QE\").replace(0, np.nan)\nbowen_daily = bowen.resample(\"D\").mean()\nbowen_daily.plot(ax=ax)\nax.set_ylabel(\"Bowen Ratio (QH/QE)\")\nax.set_title(\"Daily Bowen Ratio\")\nax.set_ylim(-2, 5)\nax.axhline(y=1, color=\"r\", linestyle=\"--\", alpha=0.5, label=\"Bowen=1\")\nax.legend()\n\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Temperature Analysis\n\nAnalyse air and surface temperature patterns.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t2 = get_var(output, \"T2\")\ntsurf = get_var(output, \"Tsurf\")\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Temperature time series\nax = axes[0, 0]\nt2.resample(\"D\").mean().plot(ax=ax, label=\"T2 (2m air)\")\ntsurf.resample(\"D\").mean().plot(ax=ax, label=\"Tsurf (surface)\")\nax.set_ylabel(\"Temperature (degC)\")\nax.set_title(\"Daily Mean Temperatures\")\nax.legend()\n\n# 2. Temperature distribution\nax = axes[0, 1]\nax.hist(t2.dropna(), bins=50, alpha=0.7, label=\"T2\", density=True)\nax.hist(tsurf.dropna(), bins=50, alpha=0.7, label=\"Tsurf\", density=True)\nax.set_xlabel(\"Temperature (degC)\")\nax.set_ylabel(\"Density\")\nax.set_title(\"Temperature Distribution\")\nax.legend()\n\n# 3. Diurnal temperature cycle by season\nax = axes[1, 0]\nfor season_name, months in [\n    (\"Winter\", [12, 1, 2]),\n    (\"Spring\", [3, 4, 5]),\n    (\"Summer\", [6, 7, 8]),\n    (\"Autumn\", [9, 10, 11]),\n]:\n    mask = t2.index.month.isin(months)\n    hourly = t2[mask].groupby(t2[mask].index.hour).mean()\n    ax.plot(hourly.index, hourly.values, marker=\"o\", markersize=3, label=season_name)\nax.set_xlabel(\"Hour of Day\")\nax.set_ylabel(\"T2 (degC)\")\nax.set_title(\"Seasonal Diurnal Temperature Cycles\")\nax.legend()\n\n# 4. Surface-air temperature difference\nax = axes[1, 1]\ndelta_t = tsurf - t2\ndelta_t_hourly = delta_t.groupby(delta_t.index.hour).mean()\nax.plot(delta_t_hourly.index, delta_t_hourly.values, \"ko-\")\nax.set_xlabel(\"Hour of Day\")\nax.set_ylabel(\"Tsurf - T2 (degC)\")\nax.set_title(\"Surface-Air Temperature Difference\")\nax.axhline(y=0, color=\"r\", linestyle=\"--\", alpha=0.5)\nax.fill_between(delta_t_hourly.index, 0, delta_t_hourly.values, where=delta_t_hourly.values > 0, alpha=0.3, color=\"red\", label=\"Surface warmer\")\nax.fill_between(delta_t_hourly.index, 0, delta_t_hourly.values, where=delta_t_hourly.values < 0, alpha=0.3, color=\"blue\", label=\"Air warmer\")\nax.legend()\n\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation Statistics\n\nCalculate standard validation metrics for model-observation comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def validation_statistics(observed, modelled):\n    \"\"\"Calculate validation statistics.\n\n    Parameters\n    ----------\n    observed : Series\n        Observed values\n    modelled : Series\n        Modelled values (aligned with observed)\n\n    Returns\n    -------\n    dict\n        Validation statistics including bias, RMSE, R2, and IoA\n    \"\"\"\n    # Align data\n    obs, mod = observed.align(modelled, join=\"inner\")\n    obs = obs.dropna()\n    mod = mod.loc[obs.index].dropna()\n\n    # Re-align after dropna\n    obs, mod = obs.align(mod, join=\"inner\")\n\n    n = len(obs)\n    if n < 3:\n        return {\"n\": n, \"error\": \"Insufficient data\"}\n\n    mean_obs = obs.mean()\n    mean_mod = mod.mean()\n\n    # Bias\n    bias = mean_mod - mean_obs\n\n    # RMSE\n    rmse = np.sqrt(((mod - obs) ** 2).mean())\n\n    # Correlation\n    r, p = stats.pearsonr(obs, mod)\n\n    # Mean Absolute Error\n    mae = (mod - obs).abs().mean()\n\n    # Index of Agreement d1 (Willmott, 1981, doi:10.1080/02723646.1981.10642213)\n    numer = ((mod - obs) ** 2).sum()\n    denom_terms = ((mod - mean_obs).abs() + (obs - mean_obs).abs()) ** 2\n    ioa = 1 - numer / denom_terms.sum() if denom_terms.sum() > 0 else np.nan\n\n    return {\n        \"n\": n,\n        \"mean_obs\": mean_obs,\n        \"mean_mod\": mean_mod,\n        \"bias\": bias,\n        \"rmse\": rmse,\n        \"mae\": mae,\n        \"r\": r,\n        \"r2\": r**2,\n        \"p_value\": p,\n        \"ioa\": ioa,\n    }\n\n\n# Example: Compare modelled T2 with forcing Tair (as proxy for \"observations\")\n# In practice, you would load actual observation data\ntair_forcing = sim.forcing.df[\"Tair\"]\nt2_model = get_var(output, \"T2\")\n\nstats_t2 = validation_statistics(tair_forcing, t2_model)\nprint(\"T2 vs Forcing Tair (demonstration):\")\nfor key, val in stats_t2.items():\n    if isinstance(val, float):\n        print(f\"  {key}: {val:.3f}\")\n    else:\n        print(f\"  {key}: {val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation Scatter Plot\n\nCreate a scatter plot comparing model output with observations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def validation_scatter(observed, modelled, variable_name, units=\"\", ax=None):\n    \"\"\"Create validation scatter plot with statistics.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(8, 8))\n\n    obs, mod = observed.align(modelled, join=\"inner\")\n    obs = obs.dropna()\n    mod = mod.loc[obs.index].dropna()\n    obs, mod = obs.align(mod, join=\"inner\")\n\n    ax.scatter(obs, mod, alpha=0.1, s=5)\n\n    # 1:1 line\n    lims = [min(obs.min(), mod.min()), max(obs.max(), mod.max())]\n    ax.plot(lims, lims, \"k--\", label=\"1:1 line\", linewidth=2)\n\n    # Regression line\n    slope, intercept = np.polyfit(obs, mod, 1)\n    ax.plot(lims, [slope * x + intercept for x in lims], \"r-\", label=f\"Fit: y = {slope:.2f}x + {intercept:.2f}\", linewidth=2)\n\n    # Statistics annotation\n    stats_dict = validation_statistics(observed, modelled)\n    stats_text = f\"n = {stats_dict['n']}\\n\" f\"$R^2$ = {stats_dict['r2']:.3f}\\n\" f\"RMSE = {stats_dict['rmse']:.2f}\\n\" f\"Bias = {stats_dict['bias']:.2f}\"\n    ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, verticalalignment=\"top\", fontsize=10, bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8))\n\n    ax.set_xlabel(f\"Observed {variable_name} ({units})\")\n    ax.set_ylabel(f\"Modelled {variable_name} ({units})\")\n    ax.set_title(f\"{variable_name} Validation\")\n    ax.legend(loc=\"lower right\")\n    ax.set_aspect(\"equal\", adjustable=\"box\")\n\n    return ax\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nvalidation_scatter(tair_forcing, t2_model, \"Air Temperature\", \"degC\", ax=ax)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exporting Results\n\nSave results in various formats for further analysis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Export to CSV\nexport_vars = [\"QN\", \"QH\", \"QE\", \"QS\", \"T2\", \"RH2\"]\nexport_df = get_vars(output, export_vars)\n# export_df.to_csv('suews_output.csv')  # Uncomment to save\nprint(f\"Export DataFrame shape: {export_df.shape}\")\nprint(f\"Ready to save with: export_df.to_csv('suews_output.csv')\")\n\n# Export final state for restart runs\nfinal_state = sim.state_final\n# final_state.to_csv('final_state.csv')  # Uncomment to save\nprint(f\"\\nFinal state shape: {final_state.shape}\")\nprint(\"Ready to save with: final_state.to_csv('final_state.csv')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\nKey analysis techniques covered:\n\n1. **Access variables** with ``get_variable()`` or MultiIndex indexing\n2. **Check balance closure** - energy and water budgets should close\n3. **Seasonal patterns** - use ``groupby()`` with month/quarter\n4. **Diurnal patterns** - use ``groupby()`` with hour\n5. **Validation metrics** - RMSE, bias, R\\ :sup:`2`, Index of Agreement\n6. **Export results** - CSV for spreadsheets, Parquet for large datasets\n\nFor external model coupling, see :doc:`tutorial_06_external_coupling`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}