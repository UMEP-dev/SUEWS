from typing import (
    Dict,
    List,
    Optional,
    Union,
    Literal,
    Tuple,
    Type,
    Generic,
    TypeVar,
    ClassVar,
    Any,
)
from pydantic import (
    ConfigDict,
    BaseModel,
    Field,
    model_validator,
    field_validator,
    PrivateAttr,
    conlist,
    ValidationError,
)
import numpy as np
import pandas as pd
import yaml
import ast

import calendar
import csv
import os
from copy import deepcopy
from pathlib import Path
import warnings

from .model import Model, OutputConfig
from .site import Site, SiteProperties, InitialStates, LandCover, LAIParams
from .type import SurfaceType

from datetime import datetime
import pytz

from types import SimpleNamespace

# Optional import of logger - use standalone if supy not available
try:
    from ..._env import logger_supy
except ImportError:
    import logging

    logger_supy = logging.getLogger("supy.data_model")
    if not logger_supy.handlers:
        handler = logging.StreamHandler()
        handler.setFormatter(
            logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        )
        logger_supy.addHandler(handler)
        logger_supy.setLevel(logging.INFO)

from ..validation.pipeline.yaml_annotator import YAMLAnnotator

_validation_available = False
enhanced_from_yaml_validation = None
enhanced_to_df_state_validation = None

import os
import warnings

SAME_ALB_TOL = 1e-6  # Tolerance for same albedo checks

class ConditionalValidationWarning(UserWarning):
    """Warning issued when conditional validation is requested but not available.

    This warning indicates that the enhanced validation feature has been requested
    via use_conditional_validation=True, but the validation module is not loaded.
    The conversion will proceed without additional validation checks.

    To suppress this warning, either:
    - Set use_conditional_validation=False when calling to_df_state()
    - Filter with: warnings.filterwarnings('ignore', category=ConditionalValidationWarning)
    """

    pass


def _unwrap_value(val):
    """
    Unwrap RefValue and Enum values consistently.

    This helper ensures consistent handling of RefValue wrappers and Enum values
    throughout the validation logic.

    Args:
        val: The value to unwrap (could be RefValue, Enum, or raw value)

    Returns:
        The unwrapped raw value
    """
    # Handle RefValue wrapper
    if (
        hasattr(val, "value")
        and hasattr(val, "__class__")
        and "RefValue" in val.__class__.__name__
    ):
        val = val.value

    # Handle Enum values (which also have .value attribute)
    if (
        hasattr(val, "value")
        and hasattr(val, "__class__")
        and "Enum" in str(val.__class__.__bases__)
    ):
        val = val.value

    return val


def _is_valid_layer_array(field) -> bool:
    return (
        hasattr(field, "value")
        and isinstance(field.value, list)
        and len(field.value) > 0
    )


class SUEWSConfig(BaseModel):
    """Main SUEWS configuration."""

    model_config = ConfigDict(title="SUEWS Configuration")

    name: str = Field(
        default="sample config",
        description="Name of the SUEWS configuration",
        json_schema_extra={"display_name": "Configuration Name"},
    )
    schema_version: Optional[str] = Field(
        default="0.1",
        description="Configuration schema version (e.g., '0.1', '1.0', '1.1'). Only changes when configuration structure changes.",
        json_schema_extra={"display_name": "Schema Version"},
    )
    description: str = Field(
        default="this is a sample config for testing purposes ONLY - values are not realistic",
        description="Description of this SUEWS configuration",
        json_schema_extra={"display_name": "Configuration Description"},
    )
    model: Model = Field(
        default_factory=Model,
        description="Model control and physics parameters",
        json_schema_extra={"display_name": "Model Parameters"},
    )
    sites: List[Site] = Field(
        default_factory=list,
        description="List of sites to simulate",
        min_length=1,
        json_schema_extra={"display_name": "Sites"},
    )

    model_config = ConfigDict(extra="allow")

    # Class-level constant for STEBBS validation parameters
    STEBBS_REQUIRED_PARAMS: ClassVar[List[str]] = [
        "WallInternalConvectionCoefficient",
        "InternalMassConvectionCoefficient",
        "FloorInternalConvectionCoefficient",
        "WindowInternalConvectionCoefficient",
        "WallExternalConvectionCoefficient",
        "WindowExternalConvectionCoefficient",
        "GroundDepth",
        "ExternalGroundConductivity",
        "MetabolismThreshold",
        "LatentSensibleRatio",
        "ApplianceProfile",
        "HeatingSystemEfficiency",
        "MaxCoolingPower",
        "CoolingSystemCOP",
        "VentilationRate",
        "InitialOutdoorTemperature",
        "InitialIndoorTemperature",
        "DeepSoilTemperature",
        "WaterTankWallThickness",
        "MainsWaterTemperature",
        "WaterTankSurfaceArea",
        "HotWaterHeatingSetpointTemperature",
        "HotWaterTankWallEmissivity",
        "DHWVesselWallThickness",
        "DHWWaterVolume",
        "DHWSurfaceArea",
        "HotWaterFlowRate",
        "HotWaterFlowProfile",
        "DHWSpecificHeatCapacity",
        "HotWaterTankSpecificHeatCapacity",
        "DHWVesselSpecificHeatCapacity",
        "DHWDensity",
        "HotWaterTankWallDensity",
        "DHWVesselDensity",
        "HotWaterTankBuildingWallViewFactor",
        "HotWaterTankInternalMassViewFactor",
        "HotWaterTankWallConductivity",
        "HotWaterTankInternalWallConvectionCoefficient",
        "HotWaterTankExternalWallConvectionCoefficient",
        "DHWVesselWallConductivity",
        "DHWVesselInternalWallConvectionCoefficient",
        "DHWVesselExternalWallConvectionCoefficient",
        "DHWVesselWallEmissivity",
        "HotWaterHeatingEfficiency",
        "MinimumVolumeOfDHWinUse",
        "MaximumVolumeOfDHWinUse",
    ]

    ARCHETYPE_REQUIRED_PARAMS: ClassVar[List[str]] = [
        "BuildingType",
        "BuildingName",
        "BuildingCount",
        "Occupants",
        "MetabolismProfile",
        "stebbs_Height",
        "FootprintArea",
        "WallExternalArea",
        "RatioInternalVolume",
        "WWR",
        "WallThickness",
        "WallEffectiveConductivity",
        "WallDensity",
        "WallCp",
        "WallOuterCapFrac",
        "WallExternalEmissivity",
        "WallInternalEmissivity",
        "WallTransmissivity",
        "WallAbsorbtivity",
        "WallReflectivity",
        "FloorThickness",
        "GroundFloorEffectiveConductivity",
        "GroundFloorDensity",
        "GroundFloorCp",
        "WindowThickness",
        "WindowEffectiveConductivity",
        "WindowDensity",
        "WindowCp",
        "WindowExternalEmissivity",
        "WindowInternalEmissivity",
        "WindowTransmissivity",
        "WindowAbsorbtivity",
        "WindowReflectivity",
        "InternalMassDensity",
        "InternalMassCp",
        "InternalMassEmissivity",
        "MaxHeatingPower",
        "WaterTankWaterVolume",
        "MaximumHotWaterHeatingPower",
        "HeatingSetpointTemperature",
        "CoolingSetpointTemperature",
    ]

    # Sort the filtered columns numerically
    @staticmethod
    def sort_key(col):
        try:
            return (col[0], ast.literal_eval(col[1]))
        except ValueError:
            return (col[0], col[1])

    @model_validator(mode="after")
    def validate_parameter_completeness(self) -> "SUEWSConfig":
        """
        Validate all parameters after full construction.
        This runs AFTER all values have been populated from YAML.
        """
        ### 1) Initialize the summary of validation issues
        self._validation_summary = {
            "total_warnings": 0,
            "sites_with_issues": [],
            "issue_types": set(),
            "yaml_path": getattr(self, "_yaml_path", None),
            "detailed_messages": [],
            "info_messages": [],
        }

        ### 2) Run the standard site-by-site checks
        for i, site in enumerate(self.sites):
            self._validate_site_parameters(site, site_index=i)

        ### 3) Run any conditional validations (e.g. STEBBS when stebbsmethod==1)
        cond_issues = self._validate_conditional_parameters()

        ### 4) Check for critical null physics parameters
        critical_nulls = self._check_critical_null_physics_params()

        ### 5) If we have either conditional issues or critical nulls, raise validation error
        all_critical_issues = []
        if cond_issues:
            all_critical_issues.extend(cond_issues)
        if critical_nulls:
            all_critical_issues.extend(critical_nulls)

        if all_critical_issues:
            # Put each critical issue on its own line for readability
            error_message = "\n".join(all_critical_issues)
            raise ValueError(f"Critical validation failed:\n{error_message}")

        ### 4) If there were any warnings, show the summary (only for non-conditional issues)
        if self._validation_summary["total_warnings"] > 0:
            self._show_validation_summary()

        return self

    @model_validator(mode="after")
    def validate_schema_compatibility(self) -> "SUEWSConfig":
        """
        Check if the configuration schema version is compatible.
        Issues warnings when there's a compatibility concern.
        """
        from ..schema import validate_schema_version, CURRENT_SCHEMA_VERSION

        # If no schema version specified, set to current
        if self.schema_version is None:
            self.schema_version = CURRENT_SCHEMA_VERSION

        # Validate compatibility (will warn if incompatible)
        validate_schema_version(self.schema_version, strict=False)

        # Log to detailed messages for validation summary if needed
        if (
            hasattr(self, "_validation_summary")
            and self.schema_version != CURRENT_SCHEMA_VERSION
        ):
            self._validation_summary["detailed_messages"].append(
                f"Schema version: Config uses {self.schema_version}, current is {CURRENT_SCHEMA_VERSION}"
            )

        return self

    @model_validator(mode="after")
    def validate_model_output_config(self) -> "SUEWSConfig":
        """
        Validate output configuration, especially frequency vs timestep.
        Migrated from Model class to SUEWSConfig for more comprehensive validation.
        """
        if isinstance(self.model.control.output_file, OutputConfig):
            output_config = self.model.control.output_file
            if output_config.freq is not None:
                # Validate frequency is positive
                if output_config.freq <= 0:
                    raise ValueError(
                        f"Output frequency must be positive, got {output_config.freq}s"
                    )

                tstep = self.model.control.tstep
                if output_config.freq % tstep != 0:
                    raise ValueError(
                        f"Output frequency ({output_config.freq}s) must be a multiple of timestep ({tstep}s)"
                    )
        elif (
            isinstance(self.model.control.output_file, str)
            and self.model.control.output_file != "output.txt"
        ):
            # Issue warning for non-default string values
            import warnings

            warnings.warn(
                f"The 'output_file' parameter with value '{self.model.control.output_file}' is deprecated and was never used. "
                "Please use the new OutputConfig format or remove this parameter. "
                "Example: output_file: {format: 'parquet', freq: 3600}",
                DeprecationWarning,
                stacklevel=3,
            )
        return self

    @model_validator(mode="after")
    def validate_model_radiation_method(self) -> "SUEWSConfig":
        """
        Validate radiation method configuration compatibility with forcing file.
        Migrated from Model class to SUEWSConfig for comprehensive validation.
        """
        # Use the helper for consistent unwrapping
        netradiationmethod_val = _unwrap_value(self.model.physics.netradiationmethod)
        forcing_file_val = _unwrap_value(self.model.control.forcing_file)

        # Check for the sample forcing file - this is still based on filename
        # TODO: Future improvement - add a flag to indicate sample forcing or check actual column presence
        # For now, we check both common sample forcing filenames
        sample_forcing_names = ["forcing.txt", "sample_forcing.txt", "test_forcing.txt"]

        if netradiationmethod_val == 1 and any(
            name in str(forcing_file_val).lower() for name in sample_forcing_names
        ):
            import warnings

            warnings.warn(
                f"NetRadiationMethod is set to 1 (using observed Ldown) with what appears to be a sample forcing file '{forcing_file_val}'. "
                "Sample forcing files typically lack observed Ldown data. "
                "If this is sample data, use netradiationmethod = 3. "
                "If this is real data with Ldown, consider renaming the file to avoid this warning.",
                UserWarning,
                stacklevel=2,
            )
        return self

    @model_validator(mode="after")
    def validate_site_required_fields(self) -> "SUEWSConfig":
        """
        Validate that all sites have required fields with valid values.
        Migrated from SiteProperties.validate_required_fields for centralized validation.

        Checks:
        - Presence of critical site properties like lat, lng, alt, timezone
        - RefValue wrapper validation
        - Physical constraint validation (z0m_in < zdm_in)
        """
        from .type import RefValue  # Import here to avoid circular import

        errors = []

        # Required fields that must be present and non-None
        required_fields = [
            "lat",
            "lng",
            "alt",
            "timezone",
            "surfacearea",
            "z",
            "z0m_in",
            "zdm_in",
            "pipecapacity",
            "runofftowater",
            "narp_trans_site",
            "lumps",
            "spartacus",
            "conductance",
            "irrigation",
            "anthropogenic_emissions",
            "snow",
            "land_cover",
            "vertical_layers",
        ]

        for i, site in enumerate(self.sites):
            if not site.properties:
                errors.append(
                    f"Site {i} ({getattr(site, 'name', 'unnamed')}) is missing properties"
                )
                continue

            site_name = getattr(site, "name", f"Site {i}")

            # Check required fields
            for field in required_fields:
                value = getattr(site.properties, field, None)
                if value is None:
                    errors.append(f"{site_name}: Required field '{field}' is missing")
                elif isinstance(value, RefValue) and value.value is None:
                    errors.append(f"{site_name}: Required field '{field}' has no value")

            # Additional physical constraint validation
            if (
                site.properties.z0m_in is not None
                and site.properties.zdm_in is not None
            ):
                z0m_val = _unwrap_value(site.properties.z0m_in)
                zdm_val = _unwrap_value(site.properties.zdm_in)
                if z0m_val is not None and zdm_val is not None and z0m_val >= zdm_val:
                    errors.append(
                        f"{site_name}: z0m_in ({z0m_val}) must be less than zdm_in ({zdm_val})"
                    )

        if errors:
            raise ValueError("; ".join(errors))

        return self

    @model_validator(mode="after")
    def validate_snow_parameters(self) -> "SUEWSConfig":
        """
        Validate snow parameters for all sites in the configuration.
        Migrated from SnowParams.validate_all for centralized validation.

        Checks:
        - crwmin < crwmax (critical water content range)
        - snowalbmin < snowalbmax (snow albedo range)

        These are critical constraints that must be satisfied for proper
        snow modeling, so they raise ValidationError rather than warnings.
        """
        from .type import RefValue  # Import here to avoid circular import

        errors = []

        for i, site in enumerate(self.sites):
            if not site.properties or not site.properties.snow:
                continue

            site_name = getattr(site, "name", f"Site {i}")
            snow_params = site.properties.snow

            # Extract values using helper for consistent unwrapping
            crwmin_val = _unwrap_value(snow_params.crwmin)
            crwmax_val = _unwrap_value(snow_params.crwmax)
            snowalbmin_val = _unwrap_value(snow_params.snowalbmin)
            snowalbmax_val = _unwrap_value(snow_params.snowalbmax)

            # Validate critical water content range
            if crwmin_val >= crwmax_val:
                errors.append(
                    f"{site_name}: crwmin ({crwmin_val}) must be less than crwmax ({crwmax_val})"
                )

            # Validate physical bounds for critical water content
            if not (0 <= crwmin_val <= 1):
                errors.append(
                    f"{site_name}: crwmin ({crwmin_val}) must be in range [0, 1]"
                )
            if not (0 <= crwmax_val <= 1):
                errors.append(
                    f"{site_name}: crwmax ({crwmax_val}) must be in range [0, 1]"
                )

            # Validate physical bounds for snow albedo
            if not (0 <= snowalbmin_val <= 1):
                errors.append(
                    f"{site_name}: snowalbmin ({snowalbmin_val}) must be in range [0, 1]"
                )
            if not (0 <= snowalbmax_val <= 1):
                errors.append(
                    f"{site_name}: snowalbmax ({snowalbmax_val}) must be in range [0, 1]"
                )

            # Validate snow albedo range
            if snowalbmin_val >= snowalbmax_val:
                errors.append(
                    f"{site_name}: snowalbmin ({snowalbmin_val}) must be less than snowalbmax ({snowalbmax_val})"
                )

        if errors:
            raise ValueError("; ".join(errors))

        return self

    @model_validator(mode="after")
    def set_default_vegetation_albedo(self) -> "SUEWSConfig":
        """Auto-calculate initial vegetation albedo from LAI state when missing.

        The relationship between canopy albedo and LAI differs between vegetation
        types. As stated in Omidvar et al. (2022) Section 4.1: "For evergreen and
        deciduous trees, alpha_LAI,min (alpha_LAI,max) in Eq. (6) typically
        corresponds to alpha_min (alpha_max), while for grassland a reverse
        relation holds (i.e. alpha_LAI,min corresponds to alpha_max and vice versa)."

        **Trees (evetr, dectr) - Direct relationship (higher LAI -> higher albedo):**

        Tree canopies have dark bark and branches as the background surface.
        At low LAI (sparse canopy), dark woody elements are visible through gaps,
        reducing overall albedo. At high LAI (dense foliage), leaves with higher
        reflectance dominate the surface.

        Formula: alb_id = alb_min + (alb_max - alb_min) * lai_ratio

        **Grass - Reversed relationship (higher LAI -> lower albedo):**

        Grass surfaces have bright soil or litter as the background. At low LAI
        (sparse grass), exposed soil with higher reflectance increases overall
        albedo. At high LAI (dense grass), green blades with lower reflectance
        dominate. Empirical evidence from Mu et al. (2024) shows a significant
        negative correlation (r = -0.462, P < 0.01) between EVI and albedo in
        East Asian grasslands.

        Formula: alb_id = alb_max - (alb_max - alb_min) * lai_ratio

        References:
            - Omidvar et al. (2022). Geosci. Model Dev., 15, 3041-3078.
              https://doi.org/10.5194/gmd-15-3041-2022
            - Mu et al. (2024). Ecological Processes.
              https://doi.org/10.1186/s13717-024-00493-w
            - Cescatti et al. (2012). Remote Sens. Environ., 121, 323-334.
              https://doi.org/10.1016/j.rse.2012.02.019
            - Song (1999). Int. J. Biometeorol., 42(3), 153-157.
              https://doi.org/10.1007/s004840050099
        """
        for site in self.sites:
            if (
                not site.initial_states
                or not site.properties
                or not site.properties.land_cover
            ):
                continue

            land_cover = site.properties.land_cover
            initial_states = site.initial_states

            vegetated_surfaces = [
                (land_cover.evetr, initial_states.evetr, False),
                (land_cover.dectr, initial_states.dectr, False),
                (land_cover.grass, initial_states.grass, True),
            ]

            for surface_props, surface_state, is_grass in vegetated_surfaces:
                if surface_props is None or surface_state is None:
                    continue

                alb_val = _unwrap_value(getattr(surface_state, "alb_id", None))
                if alb_val is not None:
                    continue

                lai_val = _unwrap_value(getattr(surface_state, "lai_id", None))
                if lai_val is None:
                    continue

                lai_params = getattr(surface_props, "lai", None)
                if lai_params is None:
                    continue

                lai_min_val = _unwrap_value(getattr(lai_params, "laimin", None))
                lai_max_val = _unwrap_value(getattr(lai_params, "laimax", None))
                # Fallback: LAIParams.laimin defaults to 0.1; LAIParams.laimax
                # defaults to None (the DataFrame serialisation path in
                # LAIParams.to_df_state uses 10.0 as its fallback).
                if lai_min_val is None:
                    lai_min_val = LAIParams.model_fields["laimin"].default
                if lai_max_val is None:
                    lai_max_val = LAIParams.LAIMAX_DF_DEFAULT

                lai_range = lai_max_val - lai_min_val
                if lai_range <= 0:
                    lai_ratio = 0.0
                else:
                    lai_ratio = (lai_val - lai_min_val) / lai_range
                    lai_ratio = min(max(lai_ratio, 0.0), 1.0)

                alb_min_val = _unwrap_value(surface_props.alb_min)
                alb_max_val = _unwrap_value(surface_props.alb_max)
                if alb_min_val is None or alb_max_val is None:
                    continue

                alb_range = alb_max_val - alb_min_val
                if is_grass:
                    alb_calc = alb_max_val - alb_range * lai_ratio
                else:
                    alb_calc = alb_min_val + alb_range * lai_ratio

                # Intentional in-place mutation of the Pydantic model instance.
                # model_validator(mode='after') receives the fully-constructed
                # object, so attribute assignment is safe here. This runs before
                # validate_albedo_ranges (validators execute in definition order).
                surface_state.alb_id = alb_calc

        return self

    @model_validator(mode="after")
    def validate_albedo_ranges(self) -> "SUEWSConfig":
        """
        Validate albedo ranges for vegetated surfaces in all sites.
        Migrated from VegetatedSurfaceProperties.validate_albedo_range for centralized validation.

        Checks:
        - alb_min <= alb_max for all vegetated surfaces (evetr, dectr, grass)

        This ensures proper albedo parameter ranges for vegetation modeling.

        NOTE: This validator depends on set_default_vegetation_albedo running
        first (Pydantic v2 executes model_validators in definition order).
        Do not reorder these validators.
        """
        from .type import RefValue  # Import here to avoid circular import

        errors = []

        for i, site in enumerate(self.sites):
            if not site.properties or not site.properties.land_cover:
                continue

            site_name = getattr(site, "name", f"Site {i}")
            land_cover = site.properties.land_cover

            # Check all vegetated surface types
            vegetated_surfaces = [
                ("evetr", land_cover.evetr, "evergreen trees"),
                ("dectr", land_cover.dectr, "deciduous trees"),
                ("grass", land_cover.grass, "grass"),
            ]

            for surface_name, surface_props, surface_description in vegetated_surfaces:
                if not surface_props:
                    continue

                # Extract albedo values using helper for consistent unwrapping
                alb_min_val = _unwrap_value(surface_props.alb_min)
                alb_max_val = _unwrap_value(surface_props.alb_max)

                # Validate physical bounds for albedo values
                if not (0 <= alb_min_val <= 1):
                    errors.append(
                        f"{site_name} {surface_description}: alb_min ({alb_min_val}) must be in range [0, 1]"
                    )
                if not (0 <= alb_max_val <= 1):
                    errors.append(
                        f"{site_name} {surface_description}: alb_max ({alb_max_val}) must be in range [0, 1]"
                    )

                # Validate albedo range - allow equality for constant albedo
                if alb_min_val > alb_max_val:
                    errors.append(
                        f"{site_name} {surface_description}: alb_min ({alb_min_val}) must be less than or equal to alb_max ({alb_max_val})"
                    )

                # Only validate alb_id range when alb_min <= alb_max
                # (the inverted case is already reported above)
                if (
                    site.initial_states
                    and hasattr(site.initial_states, surface_name)
                    and alb_min_val <= alb_max_val
                ):
                    surface_state = getattr(site.initial_states, surface_name)
                    if surface_state and hasattr(surface_state, "alb_id"):
                        alb_id_val = _unwrap_value(surface_state.alb_id)
                        if alb_id_val is not None:
                            if not (alb_min_val <= alb_id_val <= alb_max_val):
                                errors.append(
                                    f"{site_name} {surface_description}: alb_id ({alb_id_val}) must be in range [alb_min, alb_max] ([{alb_min_val}, {alb_max_val}] provided)"
                                )

        if errors:
            raise ValueError("; ".join(errors))

        return self

    @model_validator(mode="after")
    def validate_deciduous_porosity_ranges(self) -> "SUEWSConfig":
        """
        Validate porosity ranges for deciduous trees in all sites.
        Migrated from DectrProperties.validate_porosity_range for centralized validation.

        Checks:
        - pormin_dec < pormax_dec (minimum porosity < maximum porosity)

        This ensures proper porosity parameter ranges for deciduous tree modeling.
        """
        from .type import RefValue  # Import here to avoid circular import

        errors = []

        for i, site in enumerate(self.sites):
            if (
                not site.properties
                or not site.properties.land_cover
                or not site.properties.land_cover.dectr
            ):
                continue

            site_name = getattr(site, "name", f"Site {i}")
            dectr_props = site.properties.land_cover.dectr

            # Extract porosity values using helper for consistent unwrapping
            pormin_dec_val = _unwrap_value(dectr_props.pormin_dec)
            pormax_dec_val = _unwrap_value(dectr_props.pormax_dec)

            # Validate physical bounds for porosity
            if not (0 <= pormin_dec_val <= 1):
                errors.append(
                    f"{site_name} deciduous trees: pormin_dec ({pormin_dec_val}) must be in range [0, 1]"
                )
            if not (0 <= pormax_dec_val <= 1):
                errors.append(
                    f"{site_name} deciduous trees: pormax_dec ({pormax_dec_val}) must be in range [0, 1]"
                )

            # Validate porosity range
            if pormin_dec_val >= pormax_dec_val:
                errors.append(
                    f"{site_name} deciduous trees: pormin_dec ({pormin_dec_val}) must be less than pormax_dec ({pormax_dec_val})"
                )

        if errors:
            raise ValueError("; ".join(errors))

        return self

    def _show_validation_summary(self) -> None:
        """Show a concise summary of validation issues."""
        ## Check if we have a yaml path stored
        yaml_path = getattr(self, "_yaml_path", None)

        if yaml_path:
            ## When loaded from YAML, we know the source file
            yaml_path_obj = Path(yaml_path)
            annotated_path = (
                yaml_path_obj.parent / f"{yaml_path_obj.stem}_annotated.yml"
            )
            auto_generate = getattr(self, "_auto_generate_annotated", False)

            if auto_generate:
                fix_instructions = (
                    f"To see detailed fixes for each parameter: please refer to inline guidance "
                    f"in '{annotated_path}' that will be generated"
                )
            else:
                fix_instructions = (
                    f"To see detailed fixes for each parameter:\n"
                    f"   Run: config.generate_annotated_yaml('{yaml_path}')\n"
                    f"   This will create: {annotated_path}\n"
                    f"   with inline guidance showing exactly where to add missing parameters"
                )
        else:
            fix_instructions = (
                f"To see detailed fixes for each parameter:\n"
                f"   1. Save your configuration to a YAML file\n"
                f"   2. Call config.generate_annotated_yaml('your_config.yml')\n"
                f"   3. An annotated file with inline guidance will be generated"
            )

        ## Build the summary message
        summary_message = (
            f"\n{'=' * 60}\n"
            f"VALIDATION SUMMARY\n"
            f"{'=' * 60}\n"
            f"Found {self._validation_summary['total_warnings']} parameter issue(s) across "
            f"{len(self._validation_summary['sites_with_issues'])} site(s).\n\n"
        )

        ## Add issue types
        summary_message += (
            f"Issue types:\n"
            f"  - "
            + "\n  - ".join(sorted(self._validation_summary["issue_types"]))
            + "\n\n"
        )

        ## Add detailed messages if available
        if self._validation_summary.get("detailed_messages"):
            summary_message += "Detailed issues:\n"
            for msg in self._validation_summary["detailed_messages"]:
                summary_message += f"  - {msg}\n"
            summary_message += "\n"

        ## Add fix instructions
        summary_message += f"{fix_instructions}\n{'=' * 60}"

        ## Log the complete summary
        logger_supy.warning(summary_message)

        ## Optionally generate the annotated YAML file automatically
        auto_generate = getattr(self, "_auto_generate_annotated", False)
        if auto_generate and yaml_path and Path(yaml_path).exists():
            try:
                generated_path = self.generate_annotated_yaml(yaml_path)
                logger_supy.info(f"Annotated YAML file generated: {generated_path}")
            except Exception as e:
                logger_supy.info(f"Could not generate annotated YAML: {e}")

    def _validate_site_parameters(self, site: Site, site_index: int) -> None:
        """Validate all parameters for a single site."""

        if not site.properties:
            return

        site_name = getattr(site, "name", f"Site {site_index}")
        site_has_issues = False

        # Validate conductance parameters
        if hasattr(site.properties, "conductance") and site.properties.conductance:
            if self._check_conductance(site.properties.conductance, site_name):
                site_has_issues = True

        # Validate CO2 parameters
        if (
            hasattr(site.properties, "anthropogenic_emissions")
            and site.properties.anthropogenic_emissions
            and hasattr(site.properties.anthropogenic_emissions, "co2")
            and site.properties.anthropogenic_emissions.co2
        ):
            if self._check_co2_params(
                site.properties.anthropogenic_emissions.co2, site_name
            ):
                site_has_issues = True

        # Validate land cover parameters
        if hasattr(site.properties, "land_cover") and site.properties.land_cover:
            if self._check_land_cover(site.properties.land_cover, site_name):
                site_has_issues = True

        # Validate LAI range parameters
        if hasattr(site.properties, "land_cover") and site.properties.land_cover:
            if self._check_lai_ranges(site.properties.land_cover, site_name):
                site_has_issues = True

        # Track sites with issues
        if (
            site_has_issues
            and site_name not in self._validation_summary["sites_with_issues"]
        ):
            self._validation_summary["sites_with_issues"].append(site_name)

    def _check_conductance(self, conductance, site_name: str) -> bool:
        """Check for missing conductance parameters. Returns True if issues found."""
        from ..validation.core.utils import check_missing_params

        critical_params = {
            "g_max": "Maximum surface conductance",
            "g_k": "Conductance parameter for solar radiation",
            "g_sm": "Conductance parameter for soil moisture",
            "s1": "Lower soil moisture threshold",
            "s2": "Soil moisture dependence parameter",
        }

        missing_params = check_missing_params(
            critical_params,
            conductance,
            "surface conductance",
            "evapotranspiration calculations",
        )

        if missing_params:
            self._validation_summary["total_warnings"] += len(missing_params)
            self._validation_summary["issue_types"].add(
                "Missing conductance parameters"
            )
            return True
        return False

    def _check_co2_params(self, co2, site_name: str) -> bool:
        """Check for missing CO2 parameters. Returns True if issues found."""
        from ..validation.core.utils import check_missing_params

        critical_params = {
            "co2pointsource": "CO2 point source emission factor",
            "ef_umolco2perj": "CO2 emission factor per unit of fuel energy",
            "frfossilfuel_heat": "Fraction of heating energy from fossil fuels",
            "frfossilfuel_nonheat": "Fraction of non-heating energy from fossil fuels",
        }

        missing_params = check_missing_params(
            critical_params, co2, "CO2 emission", "model accuracy"
        )

        if missing_params:
            self._validation_summary["total_warnings"] += len(missing_params)
            self._validation_summary["issue_types"].add(
                "Missing CO2 emission parameters"
            )
            return True
        return False

    def _check_land_cover(self, land_cover, site_name: str) -> bool:
        """Check land cover parameters. Returns True if issues found."""
        # Check each surface type
        surface_types = ["bldgs", "grass", "dectr", "evetr", "bsoil", "paved", "water"]
        has_issues = False

        for surface_type in surface_types:
            if hasattr(land_cover, surface_type):
                surface = getattr(land_cover, surface_type)
                if surface:
                    if self._check_surface_parameters(surface, surface_type, site_name):
                        has_issues = True

        return has_issues

    def _check_surface_parameters(
        self, surface, surface_type: str, site_name: str
    ) -> bool:
        """Check parameters for a specific surface type. Returns True if issues found."""
        from ..validation.core.utils import check_missing_params

        has_issues = False

        # Get surface fraction value
        sfr_value = 0
        if hasattr(surface, "sfr") and surface.sfr is not None:
            sfr_value = getattr(surface.sfr, "value", surface.sfr)

        # Only validate if surface fraction > 0
        if sfr_value > 0:
            # Check building-specific parameters
            if surface_type == "bldgs" and sfr_value > 0.05:
                missing_params = []

                if not hasattr(surface, "bldgh") or surface.bldgh is None:
                    missing_params.append("bldgh (Building height)")
                if not hasattr(surface, "faibldg") or surface.faibldg is None:
                    missing_params.append("faibldg (Frontal area index)")

                if missing_params:
                    self._validation_summary["total_warnings"] += len(missing_params)
                    self._validation_summary["issue_types"].add(
                        "Missing building parameters"
                    )
                    has_issues = True

            # Check vegetation parameters for grass, dectr, evetr
            if surface_type in ["grass", "dectr", "evetr"]:
                vegetation_params = {
                    "beta_bioco2": "Biogenic CO2 exchange coefficient",
                    "alpha_bioco2": "Biogenic CO2 exchange coefficient",
                    "resp_a": "Respiration coefficient",
                    "resp_b": "Respiration coefficient",
                }

                missing_params = check_missing_params(
                    vegetation_params, surface, "vegetation", "CO2 flux calculations"
                )

                if missing_params:
                    self._validation_summary["total_warnings"] += len(missing_params)
                    self._validation_summary["issue_types"].add(
                        "Missing vegetation parameters"
                    )
                    has_issues = True

            # Check thermal layers only for surfaces that typically need them
            # or where user has explicitly provided non-None values
            if hasattr(surface, "thermal_layers") and surface.thermal_layers:
                # Only validate if at least one thermal property is explicitly set
                thermal_layers = surface.thermal_layers
                has_thermal_data = (
                    (hasattr(thermal_layers, "dz") and thermal_layers.dz is not None)
                    or (hasattr(thermal_layers, "k") and thermal_layers.k is not None)
                    or (
                        hasattr(thermal_layers, "rho_cp")
                        and thermal_layers.rho_cp is not None
                    )
                )

                if has_thermal_data:
                    if self._check_thermal_layers(
                        surface.thermal_layers, surface_type, site_name
                    ):
                        has_issues = True

        return has_issues

    def _check_thermal_layers(
        self, thermal_layers, surface_type: str, site_name: str
    ) -> bool:
        """Check thermal layer parameters. Returns True if issues found."""
        missing_params = []

        def _is_valid_layer_array(field):
            # Handle both RefValue wrappers and plain lists
            if hasattr(field, "value") and isinstance(field.value, list):
                # RefValue wrapper case
                return len(field.value) > 0
            elif isinstance(field, list):
                # Plain list case
                return len(field) > 0
            else:
                # Neither RefValue nor list
                return False

        if not hasattr(thermal_layers, "dz") or not _is_valid_layer_array(
            thermal_layers.dz
        ):
            missing_params.append("dz (Layer thickness)")
        if not hasattr(thermal_layers, "k") or not _is_valid_layer_array(
            thermal_layers.k
        ):
            missing_params.append("k (Thermal conductivity)")

        missing_rho_cp = not hasattr(
            thermal_layers, "rho_cp"
        ) or not _is_valid_layer_array(thermal_layers.rho_cp)
        if missing_rho_cp:
            missing_params.append("rho_cp (Volumetric heat capacity)")

        if missing_params:
            # Check if this is a cp naming issue (cp instead of rho_cp)
            yaml_path = getattr(self, "_yaml_path", None)
            surface_path = f"sites/0/properties/land_cover/{surface_type}"

            if (
                missing_rho_cp
                and yaml_path
                and self._check_raw_yaml_for_cp_field(yaml_path, surface_path)
            ):
                # This is a naming issue, not a missing parameter issue
                self._validation_summary["total_warnings"] += 1
                self._validation_summary["issue_types"].add(
                    "Incorrect naming of thermal layer parameters"
                )
            else:
                # Regular missing parameters
                self._validation_summary["total_warnings"] += len(missing_params)
                self._validation_summary["issue_types"].add(
                    "Missing thermal layer parameters"
                )
            return True
        return False

    def _check_lai_ranges(self, land_cover, site_name: str) -> bool:
        """Check LAI range parameters for vegetation surfaces. Returns True if issues found."""
        has_issues = False

        # Initialize validation summary if it doesn't exist (for testing)
        if not hasattr(self, "_validation_summary"):
            self._validation_summary = {
                "total_warnings": 0,
                "sites_with_issues": [],
                "issue_types": set(),
                "yaml_path": getattr(self, "_yaml_path", None),
                "detailed_messages": [],
                "info_messages": [],
            }

        # Return early if no land cover
        if land_cover is None:
            return False

        # Check vegetation surface types that have LAI parameters
        vegetation_surfaces = ["grass", "dectr", "evetr"]

        for surface_type in vegetation_surfaces:
            if hasattr(land_cover, surface_type):
                surface = getattr(land_cover, surface_type)
                if surface and hasattr(surface, "lai"):
                    lai = surface.lai
                    if lai:
                        # Check laimin vs laimax
                        if (
                            hasattr(lai, "laimin")
                            and lai.laimin is not None
                            and hasattr(lai, "laimax")
                            and lai.laimax is not None
                        ):
                            laimin_val = (
                                lai.laimin.value
                                if hasattr(lai.laimin, "value")
                                else lai.laimin
                            )
                            laimax_val = (
                                lai.laimax.value
                                if hasattr(lai.laimax, "value")
                                else lai.laimax
                            )

                            if laimin_val > laimax_val:
                                self._validation_summary["total_warnings"] += 1
                                self._validation_summary["issue_types"].add(
                                    "LAI range validation"
                                )
                                self._validation_summary["detailed_messages"].append(
                                    f"{site_name} {surface_type}: laimin ({laimin_val}) must be <= laimax ({laimax_val})"
                                )
                                has_issues = True

                        # Check baset vs gddfull
                        if (
                            hasattr(lai, "baset")
                            and lai.baset is not None
                            and hasattr(lai, "gddfull")
                            and lai.gddfull is not None
                        ):
                            baset_val = (
                                lai.baset.value
                                if hasattr(lai.baset, "value")
                                else lai.baset
                            )
                            gddfull_val = (
                                lai.gddfull.value
                                if hasattr(lai.gddfull, "value")
                                else lai.gddfull
                            )

                            if baset_val > gddfull_val:
                                self._validation_summary["total_warnings"] += 1
                                self._validation_summary["issue_types"].add(
                                    "LAI range validation"
                                )
                                self._validation_summary["detailed_messages"].append(
                                    f"{site_name} {surface_type}: baset ({baset_val}) must be <= gddfull ({gddfull_val})"
                                )
                                has_issues = True

        return has_issues

    def _check_raw_yaml_for_cp_field(self, yaml_path: str, surface_path: str) -> bool:
        """Check if the raw YAML file has 'cp' instead of 'rho_cp' in thermal_layers."""
        try:
            import yaml

            with open(yaml_path, "r") as f:
                data = yaml.safe_load(f)

            # Navigate to the surface using path like "sites[0]/properties/land_cover/paved"
            path_parts = surface_path.replace("[", "/").replace("]", "").split("/")

            current = data
            for part in path_parts:
                if part.isdigit():
                    current = current[int(part)]
                elif part in current:
                    current = current[part]
                else:
                    return False

            # Check if thermal_layers has 'cp' field
            if isinstance(current, dict) and "thermal_layers" in current:
                thermal_layers = current["thermal_layers"]
                if isinstance(thermal_layers, dict) and "cp" in thermal_layers:
                    return True

        except Exception:
            pass

        return False

    def _check_thermal_layers_naming_issue(
        self, thermal_layers, surface_type: str, site_name: str
    ) -> bool:
        """Check for thermal layer naming issues (cp vs rho_cp). Returns True if issues found."""
        self._validation_summary["total_warnings"] += 1
        self._validation_summary["issue_types"].add(
            "Incorrect naming of thermal layer parameters"
        )
        if site_name not in self._validation_summary["sites_with_issues"]:
            self._validation_summary["sites_with_issues"].append(site_name)
        return True

    def _needs_stebbs_validation(self) -> bool:
        """
        Return True if STEBBS should be validated,
        i.e. physics.stebbsmethod == 1.
        """

        if not hasattr(self.model, "physics") or not hasattr(
            self.model.physics, "stebbsmethod"
        ):
            return False

        stebbsmethod = self.model.physics.stebbsmethod

        if hasattr(stebbsmethod, "value"):
            stebbsmethod = stebbsmethod.value
        if hasattr(stebbsmethod, "__int__"):
            stebbsmethod = int(stebbsmethod)
        if isinstance(stebbsmethod, str) and stebbsmethod == "1":
            stebbsmethod = 1

        # print(f"Final stebbsmethod value for validation: {stebbsmethod} (type: {type(stebbsmethod)})")

        return stebbsmethod == 1

    def _validate_stebbs(self, site: Site, site_index: int) -> List[str]:
        """
        If stebbsmethod==1, enforce that site.properties.stebbs
        and site.properties.building_archetype have all
        required parameters with non-null values.
        Returns a list of issue messages.
        """
        issues: List[str] = []

        ## First check if properties exists and is not None
        if not hasattr(site, "properties") or site.properties is None:
            issues.append(
                "Missing 'properties' section (required for STEBBS validation)"
            )
            return issues

        props = site.properties

        ## Must have a stebbs block
        if not hasattr(props, "stebbs") or props.stebbs is None:
            issues.append("Missing 'stebbs' section (required when stebbsmethod=1)")
            return issues

        ## Must have a building_archetype block
        if not hasattr(props, "building_archetype") or props.building_archetype is None:
            # Do not return early â€” create an empty container so we can list all
            # missing ARCHETYPE_REQUIRED_PARAMS alongside missing stebbs params.
            building_archetype = SimpleNamespace()
        else:
            building_archetype = props.building_archetype

        stebbs = props.stebbs

        missing_params: List[str] = []

        # helper to check and append missing params
        def _check_required(container, param_list):
            for param in param_list:
                # existence
                if not hasattr(container, param):
                    missing_params.append(param)
                    continue
                param_obj = getattr(container, param)
                # unwrap any RefValue/Enum wrappers
                val = _unwrap_value(param_obj) if param_obj is not None else None
                if val is None:
                    missing_params.append(param)

        # Validate stebbs required params
        _check_required(stebbs, self.STEBBS_REQUIRED_PARAMS)
        # Validate building_archetype required params
        _check_required(building_archetype, self.ARCHETYPE_REQUIRED_PARAMS)

        ## Always list all missing parameters, regardless of count
        if missing_params:
            param_list = ", ".join(missing_params)
            issues.append(
                f"Missing required STEBBS parameters: {param_list} (required when stebbsmethod=1)"
            )

        return issues

    def _needs_rsl_validation(self) -> bool:
        """
        Return True if RSL diagnostic method is explicitly enabled.
        Only triggers validation if rslmethod == 2 AND the value was explicitly set
        (not just the default value).
        """
        if not hasattr(self.model, "physics") or not hasattr(
            self.model.physics, "rslmethod"
        ):
            return False

        rm = self.model.physics.rslmethod
        method = getattr(rm, "value", rm)
        try:
            method = int(method)
        except (TypeError, ValueError):
            pass

        # Only validate if method == 2 AND it was explicitly set
        if method == 2:
            # Check if this is likely a default value by checking if other physics
            # parameters are also at their defaults, suggesting the entire physics
            # section was auto-generated rather than user-specified
            return self._is_physics_explicitly_configured()

        return False

    def _validate_rsl(self, site: Site, site_index: int) -> List[str]:
        """
        If rslmethod==2, then for any site where bldgs.sfr > 0,
        bldgs.faibldg must be set and non-null.
        """
        issues: List[str] = []
        props = getattr(site, "properties", None)
        if not props or not hasattr(props, "land_cover") or not props.land_cover:
            return issues

        lc = props.land_cover
        bldgs = getattr(lc, "bldgs", None)
        if not bldgs or not hasattr(bldgs, "sfr") or bldgs.sfr is None:
            return issues

        sfr = getattr(bldgs.sfr, "value", bldgs.sfr)
        try:
            sfr = float(sfr)
        except (TypeError, ValueError):
            sfr = 0.0

        if sfr > 0:
            faibldg = getattr(bldgs, "faibldg", None)
            val = getattr(faibldg, "value", faibldg) if faibldg is not None else None
            if val is None:
                site_name = getattr(site, "name", f"Site {site_index}")
                issues.append(
                    f"{site_name}: for rslmethod=2 and bldgs.sfr={sfr}, bldgs.faibldg must be set"
                )
        return issues

    def _needs_storage_validation(self) -> bool:
        """
        Return True if DyOHM storage-heat method is explicitly enabled.
        Only triggers validation if storageheatmethod == 6 AND the value was explicitly set
        (not just the default value).
        """
        if not hasattr(self.model, "physics") or not hasattr(
            self.model.physics, "storageheatmethod"
        ):
            return False

        shm = getattr(self.model.physics.storageheatmethod, "value", None)
        try:
            shm = int(shm)
        except (TypeError, ValueError):
            pass

        # Only validate if method == 6 or 7 AND it was explicitly set
        if shm == 6 or shm == 7:
            return self._is_physics_explicitly_configured()
        return False
    
    def _needs_samealbedo_wall_validation(self) -> bool:
        """Return True if samealbedo_wall option is enabled (==1)."""
        return self._needs_samealbedo_validation("samealbedo_wall")

    def _needs_samealbedo_roof_validation(self) -> bool:
        """Return True if samealbedo_roof option is enabled (==1)."""
        return self._needs_samealbedo_validation("samealbedo_roof")

    def _needs_samealbedo_validation(self, attr: str) -> bool:
        """Helper for samealbedo_wall/roof validation."""
        physics = getattr(self.model, "physics", None)
        if not physics or not hasattr(physics, attr):
            return False
        val = getattr(getattr(physics, attr), "value", getattr(physics, attr))
        try:
            return int(val) == 1
        except (TypeError, ValueError):
            return False

    def _is_physics_explicitly_configured(self) -> bool:
        """
        Heuristic to determine if physics parameters were explicitly set by the user
        rather than using all default values.

        For now, we'll be conservative and assume that if no model section was
        provided by the user, then conditional validation should not apply.

        Returns True if physics appears to be explicitly configured.
        """
        # For now, disable conditional validation entirely for configs that
        # don't explicitly set the problematic physics methods
        # This is a conservative approach that avoids breaking existing tests

        # The real solution would be to track whether fields were explicitly set
        # vs using defaults, but that requires more complex Pydantic handling

        # For now, return False to disable conditional validation unless
        # explicitly enabled during testing
        return False

    def _validate_storage(self, site: Site, site_index: int) -> List[str]:
        issues: List[str] = []

        site_name = getattr(site, "name", f"Site {site_index}")
        props = getattr(site, "properties", None)
        states = getattr(site, "initial_states", None)
        if not props:
            return issues

        vl = getattr(props, "vertical_layers", None)
        walls = getattr(vl, "walls", None) if vl else None

        if not walls or len(walls) == 0:
            issues.append(
                f"{site_name}: storageheatmethod 6 or 7 (DyOHM) selected â†’ missing vertical_layers.walls"
            )
            return issues

        th = getattr(walls[0], "thermal_layers", None)
        for arr in ("dz", "k", "rho_cp"):
            field = getattr(th, arr, None) if th else None
            vals = getattr(field, "value", None) if field else None
            if (
                not isinstance(vals, list)
                or len(vals) == 0
                or any(v is None for v in vals)
                or any(not isinstance(v, (int, float)) for v in vals)
            ):
                issues.append(
                    f"{site_name}: storageheatmethod 6 or 7 (DyOHM) selected â†’ "
                    f"thermal_layers.{arr} must be a nonâ€empty list of numeric values (no nulls)"
                )

        for arr in ("qn_surfs", "dqndt_surf"):
            field = getattr(states, arr, None) if states else None
            # Handle both RefValue with .value and plain list
            if hasattr(field, "value"):
                vals = field.value
            else:
                vals = field
            if (
                not isinstance(vals, list)
                or len(vals) == 0
                or any(v is None for v in vals)
                or any(not isinstance(v, (int, float)) for v in vals)
            ):
                issues.append(
                    f"{site_name}: storageheatmethod 6 or 7 (DyOHM) selected â†’ "
                    f"initial_states.{arr} must be a nonâ€empty list of numeric values (no nulls)"
                )

        lam = getattr(getattr(props, "lambda_c", None), "value", None)
        if lam in (None, ""):
            issues.append(
                f"{site_name}: storageheatmethod 6 or 7 (DyOHM) selected â†’ properties.lambda_c must be set and non-null"
            )

        return issues

    def _validate_samealbedo_surface(
        self,
        site: Site,
        site_index: int,
        surface_type: str,
        layers_attr: str,
        reflectivity_attr: str,
        param_name: str,
    ) -> List[str]:
        """
        Generic validator for samealbedo_wall and samealbedo_roof.

        - All albedoes in vertical_layers.<layers_attr> must be identical
        - That common value must equal properties.building_archetype.<reflectivity_attr>
        """
        issues: List[str] = []
        site_name = getattr(site, "name", f"Site {site_index}")

        # --- Get layers and their albedoes ---
        props = getattr(site, "properties", None)
        vl = getattr(props, "vertical_layers", None) if props is not None else None
        layers = getattr(vl, layers_attr, None) if vl is not None else None

        if not layers:
            issues.append(
                f"{site_name}: {param_name}=1, so vertical_layers.{layers_attr} must be defined and non-empty"
            )
            return issues

        albs: List[float] = []

        for i, layer in enumerate(layers):
            alb_field = getattr(layer, "alb", None)
            if alb_field is None:
                issues.append(
                    f"{site_name}: {param_name}=1, so {layers_attr}[{i}].alb must be set"
                )
                continue

            val = getattr(alb_field, "value", alb_field)
            try:
                val_float = float(val)
                albs.append(val_float)
            except (TypeError, ValueError):
                issues.append(
                    f"{site_name}: {param_name}=1 but {layers_attr}[{i}].alb ({val!r}) is not numeric"
                )

        if len(albs) == 0:
            issues.append(
                f"{site_name}: {param_name}=1 but no valid {layers_attr} albedo values found"
            )
            return issues

        # --- Check that all albedoes are identical ---
        first_alb = albs[0]
        tol = SAME_ALB_TOL
        mismatching = [
            (i, a) for i, a in enumerate(albs) if abs(a - first_alb) > tol
        ]

        if mismatching:
            all_alb_str = ", ".join(f"{layers_attr}[{i}]={a}" for i, a in enumerate(albs))
            issues.append(
                f"{site_name}: {param_name}=1, so all {layers_attr} albedoes must be identical; "
                f"found values: {all_alb_str}"
            )

        # --- Get building_archetype.<reflectivity_attr> ---
        ba = getattr(props, "building_archetype", None)
        if ba is None:
            issues.append(
                f"{site_name}: {param_name}=1, so properties.building_archetype must be defined"
            )
            return issues

        refl_field = getattr(ba, reflectivity_attr, None)
        if refl_field is None:
            issues.append(
                f"{site_name}: {param_name}=1, so properties.building_archetype.{reflectivity_attr} must be set"
            )
            return issues

        refl_val = getattr(refl_field, "value", refl_field)
        try:
            reflectivity = float(refl_val)
        except (TypeError, ValueError):
            issues.append(
                f"{site_name}: {param_name}=1 but properties.building_archetype.{reflectivity_attr} "
                f"({refl_val!r}) is not numeric"
            )
            return issues

        # --- Check equality between *common* albedo and reflectivity ---
        if abs(first_alb - reflectivity) > tol:
            all_alb_str = ", ".join(f"{layers_attr}[{i}]={a}" for i, a in enumerate(albs))
            issues.append(
                f"{site_name}: {param_name}=1, so common {layers_attr} albedo (found {all_alb_str}) must equal "
                f"properties.building_archetype.{reflectivity_attr} ({reflectivity})"
            )

        return issues

    def _validate_samealbedo_wall(self, site: Site, site_index: int) -> List[str]:
        return self._validate_samealbedo_surface(
            site, site_index, "wall", "walls", "WallReflectivity", "samealbedo_wall"
        )

    def _validate_samealbedo_roof(self, site: Site, site_index: int) -> List[str]:
        return self._validate_samealbedo_surface(
            site, site_index, "roof", "roofs", "RoofReflectivity", "samealbedo_roof"
        )

    def _needs_spartacus_validation(self) -> bool:
        """
        Return True if SPARTACUS is enabled (netradiationmethod 1001, 1002, or 1003).
        """
        spartacus_methods = {1001, 1002, 1003}
        netrad_method = _unwrap_value(getattr(self.model.physics, "netradiationmethod", None))
        try:
            netrad_method = int(netrad_method)
        except (TypeError, ValueError):
            pass
        return netrad_method in spartacus_methods

    def _validate_spartacus_building_height(self, site: Site, site_index: int) -> List[str]:
        """
        If SPARTACUS is enabled, enforce that bldgh does not exceed the domain top (height[nlayer+1]).
        Returns a list of issue messages.
        """
        issues: List[str] = []
        site_name = getattr(site, "name", f"Site {site_index}")
        props = getattr(site, "properties", None)
        if not props or not hasattr(props, "land_cover") or not props.land_cover:
            return issues
        bldgs = getattr(props.land_cover, "bldgs", None)
        bldgh = _unwrap_value(getattr(bldgs, "bldgh", None)) if bldgs else None
        vertical_layers = getattr(props, "vertical_layers", None)
        height_arr = _unwrap_value(getattr(vertical_layers, "height", None)) if vertical_layers else None
        nlayer = _unwrap_value(getattr(vertical_layers, "nlayer", None)) if vertical_layers else None
        if (
            bldgh is not None and
            height_arr is not None and
            nlayer is not None and
            isinstance(height_arr, (list, tuple)) and
            len(height_arr) > nlayer
        ):
            spartacus_top = height_arr[nlayer]
            if bldgh > spartacus_top:
                issues.append(
                    f"Site '{site_name}' has bldgh={bldgh} exceeding SPARTACUS domain top (height[{nlayer+1}]={spartacus_top})."
                )
        return issues

    def _validate_spartacus_sfr(self, site: Site, site_index: int) -> list:
        """
        If SPARTACUS is enabled, check that:
        - bldgs.sfr == building_frac[0]
        - (evetr.sfr + dectr.sfr) == max(veg_frac[:])
        Returns a list of issue messages.
        """
        issues: list = []
        site_name = getattr(site, "name", f"Site {site_index}")
        props = getattr(site, "properties", None)
        if not props or not hasattr(props, "land_cover") or not props.land_cover:
            return issues

        lc = props.land_cover
        bldgs = getattr(lc, "bldgs", None)
        evetr = getattr(lc, "evetr", None)
        dectr = getattr(lc, "dectr", None)
        vertical_layers = getattr(props, "vertical_layers", None)
        if not vertical_layers:
            return issues

        # Unwrap values
        bldgs_sfr = _unwrap_value(getattr(bldgs, "sfr", None)) if bldgs else None
        evetr_sfr = _unwrap_value(getattr(evetr, "sfr", None)) if evetr else 0.0
        dectr_sfr = _unwrap_value(getattr(dectr, "sfr", None)) if dectr else 0.0
        veg_sfr = (evetr_sfr or 0.0) + (dectr_sfr or 0.0)

        building_frac = _unwrap_value(getattr(vertical_layers, "building_frac", None))
        veg_frac = _unwrap_value(getattr(vertical_layers, "veg_frac", None))

        tol = 1e-6

        # Buildings: surface fraction vs first SPARTACUS layer
        if (
            isinstance(building_frac, (list, tuple))
            and len(building_frac) > 0
            and bldgs_sfr is not None
        ):
            if not np.isclose(bldgs_sfr, building_frac[0], atol=tol):
                issues.append(
                    f"{site_name}: bldgs.sfr ({bldgs_sfr}) does not match "
                    f"vertical_layers.building_frac[0] ({building_frac[0]})"
                )

        # Vegetation: surface fraction vs maximum veg_frac across layers
        if isinstance(veg_frac, (list, tuple)) and len(veg_frac) > 0:
            veg_frac_max = max(veg_frac)
            if not np.isclose(veg_sfr, veg_frac_max, atol=tol):
                issues.append(
                    f"{site_name}: evetr.sfr + dectr.sfr ({veg_sfr}) does not match "
                    f"max(vertical_layers.veg_frac) ({veg_frac_max})"
                )

        return issues
    
    def _validate_spartacus_veg_dimensions(self, site: Site, site_index: int) -> list:
        """
        Check that veg_scale and veg_frac are zero above the layer where max_tree falls.
        max_tree = max(dectreeh, evetreeh)
        The last layer where max_tree < height[layer] (layer index 1..nlayer) is the tree layer.
        All veg_scale and veg_frac entries above this layer (i.e., layer_index+1 to nlayer) must be zero.
        """
        issues: list = []
        site_name = getattr(site, "name", f"Site {site_index}")

        vertical_layers = getattr(getattr(site, "properties", None), "vertical_layers", None)
        land_cover = getattr(getattr(site, "properties", None), "land_cover", None)

        # Get tree heights
        dectreeh = _unwrap_value(getattr(getattr(land_cover, "dectr", None), "dectreeh", None)) if land_cover and getattr(land_cover, "dectr", None) else None
        evetreeh = _unwrap_value(getattr(getattr(land_cover, "evetr", None), "evetreeh", None)) if land_cover and getattr(land_cover, "evetr", None) else None
        
        # Compute max_tree
        tree_heights = [h for h in [dectreeh, evetreeh] if h is not None]
        if not tree_heights:
            return issues  # No tree heights to check

        max_tree = max(tree_heights)

        # Get height array (should be nlayer+1)
        height_arr = _unwrap_value(getattr(vertical_layers, "height", None)) if vertical_layers else None
        if not isinstance(height_arr, (list, tuple)) or len(height_arr) < 2:
            return issues  # Not enough height info

        # Find the last layer where max_tree < height[layer] (layer index 1..nlayer)
        layer_index = None
        for i in range(1, len(height_arr)):
            if max_tree < height_arr[i]:
                layer_index = i
                break
        if layer_index is None:
            # max_tree exceeds all layers
            issues.append(
                f"Site {site_name}: max_tree ({max_tree}) exceeds all vertical_layers heights."
            )
            return issues

        # Check veg_scale and veg_frac above the tree layer (layer_index+1 to nlayer)
        veg_scale = _unwrap_value(getattr(vertical_layers, "veg_scale", None)) if vertical_layers else None
        veg_frac = _unwrap_value(getattr(vertical_layers, "veg_frac", None)) if vertical_layers else None

        nlayer = len(height_arr) - 1  # nlayer is height_arr length minus 1

        for arr_name, arr in [("veg_scale", veg_scale), ("veg_frac", veg_frac)]:
            if isinstance(arr, (list, tuple)):
                for i in range(layer_index, nlayer):
                    val = arr[i]
                    if val != 0:
                        issues.append(
                            f"Site {site_name}: {arr_name}[{i}] should be zero (provided max tree height {max_tree} does not reach height {height_arr[i+1]} of layer {i+1})."
                        )
        return issues

    def _validate_conditional_parameters(self) -> List[str]:
        """
        Run any methodâ€specific validations (STEBBS, RSL, StorageHeat) in one
        site-loop. Returns all issue messages.
        """
        all_issues: List[str] = []

        # Determine which checks to run once up front
        needs_stebbs = self._needs_stebbs_validation()
        needs_rsl = self._needs_rsl_validation()
        needs_storage = self._needs_storage_validation()
        needs_samealbedo_wall = self._needs_samealbedo_wall_validation()
        needs_samealbedo_roof = self._needs_samealbedo_roof_validation()
        needs_spartacus = self._needs_spartacus_validation()

        # Nothing to do?
        if not (needs_stebbs or needs_rsl or needs_storage or needs_samealbedo_wall or needs_samealbedo_roof or needs_spartacus):
            return all_issues

        for idx, site in enumerate(self.sites):
            site_name = getattr(site, "name", f"Site {idx}")

            # STEBBS
            if needs_stebbs:
                stebbs_issues = self._validate_stebbs(site, idx)
                if stebbs_issues:
                    self._validation_summary["issue_types"].add("STEBBS parameters")
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(stebbs_issues)

            # RSL
            if needs_rsl:
                rsl_issues = self._validate_rsl(site, idx)
                if rsl_issues:
                    self._validation_summary["issue_types"].add("RSL faibldg")
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(rsl_issues)

            # StorageHeat (DyOHM)
            if needs_storage:
                storage_issues = self._validate_storage(site, idx)
                if storage_issues:
                    self._validation_summary["issue_types"].add(
                        "StorageHeat parameters"
                    )
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(storage_issues)
            
            # samealbedo_wall
            if needs_samealbedo_wall:
                samealbedo_wall_issues = self._validate_samealbedo_wall(site, idx)
                if samealbedo_wall_issues:
                    self._validation_summary["issue_types"].add(
                        "samealbedo_wall parameters"
                    )
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(samealbedo_wall_issues)

            # samealbedo_roof
            if needs_samealbedo_roof:
                samealbedo_roof_issues = self._validate_samealbedo_roof(site, idx)
                if samealbedo_roof_issues:
                    self._validation_summary["issue_types"].add(
                        "samealbedo_roof parameters"
                    )
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(samealbedo_roof_issues)

            # SPARTACUS building height, sfr, and vegetation consistency checks
            if needs_spartacus:
                spartacus_issues = self._validate_spartacus_building_height(site, idx)
                if spartacus_issues:
                    self._validation_summary["issue_types"].add("SPARTACUS building height")
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(spartacus_issues)

                spartacus_sfr_issues = self._validate_spartacus_sfr(site, idx)
                if spartacus_sfr_issues:
                    self._validation_summary["issue_types"].add("SPARTACUS SFR")
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(spartacus_sfr_issues)

                spartacus_veg_issues = self._validate_spartacus_veg_dimensions(site, idx)
                if spartacus_veg_issues:
                    self._validation_summary["issue_types"].add("SPARTACUS vegetation layer consistency")
                    if site_name not in self._validation_summary["sites_with_issues"]:
                        self._validation_summary["sites_with_issues"].append(site_name)
                    all_issues.extend(spartacus_veg_issues)
        return all_issues

    def _check_critical_null_physics_params(self) -> List[str]:
        """
        Check for critical null physics parameters that would cause runtime crashes.
        Returns list of error messages for critical nulls.
        """
        # Critical physics parameters that get converted to int() in df_state
        CRITICAL_PHYSICS_PARAMS = [
            "netradiationmethod",
            "emissionsmethod",
            "storageheatmethod",
            "ohmincqf",
            "roughlenmommethod",
            "roughlenheatmethod",
            "stabilitymethod",
            "smdmethod",
            "waterusemethod",
            "rslmethod",
            "faimethod",
            "rsllevel",
            "gsmodel",
            "snowuse",
            "stebbsmethod",
            "rcmethod",
            "samealbedo_wall",
            "samealbedo_roof",
        ]

        critical_issues = []

        if not hasattr(self, "model") or not self.model or not self.model.physics:
            return critical_issues

        physics = self.model.physics

        for param_name in CRITICAL_PHYSICS_PARAMS:
            if hasattr(physics, param_name):
                param_value = getattr(physics, param_name)
                # Handle RefValue wrapper
                if hasattr(param_value, "value"):
                    actual_value = param_value.value
                else:
                    actual_value = param_value

                # Check if the parameter is null
                if actual_value is None:
                    critical_issues.append(
                        f"{param_name} is set to null and will cause runtime crash - must be set to appropriate non-null value"
                    )

        return critical_issues

    def generate_annotated_yaml(
        self, yaml_path: str, output_path: Optional[str] = None
    ) -> str:
        """
        Generate an annotated YAML file with validation feedback.

        Args:
            yaml_path: Path to the original YAML file
            output_path: Optional path for the annotated file

        Returns:
            Path to the generated annotated file
        """
        from pathlib import Path

        annotator = YAMLAnnotator()

        # Collect validation issues by running validation
        for i, site in enumerate(self.sites):
            site_name = getattr(site, "name", f"Site {i}")
            self._collect_validation_issues(site, site_name, i, annotator)

        # Generate annotated file
        try:
            input_path = Path(yaml_path)
            if not input_path.exists():
                logger_supy.error(f"Input file does not exist: {yaml_path}")
                return None

            if output_path:
                output_path = Path(output_path)
                # Check if output directory exists
                if not output_path.parent.exists():
                    logger_supy.error(
                        f"Output directory does not exist: {output_path.parent}"
                    )
                    return None
            else:
                output_path = input_path.parent / f"{input_path.stem}_annotated.yml"

            annotated_path = annotator.generate_annotated_file(input_path, output_path)

            logger_supy.info(f"Generated annotated YAML file: {annotated_path}")
            return str(annotated_path)
        except Exception as e:
            logger_supy.error(f"Failed to generate annotated YAML: {e}")
            return None

    def _collect_validation_issues(
        self, site: Site, site_name: str, site_index: int, annotator: YAMLAnnotator
    ) -> None:
        """Collect validation issues for annotation."""

        if not hasattr(site, "properties") or not site.properties:
            return

        # Check conductance
        if hasattr(site.properties, "conductance") and site.properties.conductance:
            from ..validation.core.utils import check_missing_params

            critical_params = {
                "g_max": "Maximum surface conductance",
                "g_k": "Conductance parameter for solar radiation",
                "g_sm": "Conductance parameter for soil moisture",
                "s1": "Lower soil moisture threshold",
                "s2": "Soil moisture dependence parameter",
            }

            missing_params = check_missing_params(
                critical_params,
                site.properties.conductance,
                "surface conductance",
                "evapotranspiration calculations",
            )

            for param, desc in critical_params.items():
                if param in missing_params:
                    annotator.add_issue(
                        path=f"sites[{site_index}]/properties/conductance",
                        param=param,
                        message=f"Missing {desc}",
                        fix=f"Add {param} value for accurate evapotranspiration",
                        level="WARNING",
                    )

        # Check CO2 parameters
        if (
            hasattr(site.properties, "anthropogenic_emissions")
            and site.properties.anthropogenic_emissions
            and hasattr(site.properties.anthropogenic_emissions, "co2")
            and site.properties.anthropogenic_emissions.co2
        ):
            from ..validation.core.utils import check_missing_params

            critical_params = {
                "co2pointsource": "CO2 point source emission factor",
                "ef_umolco2perj": "CO2 emission factor per unit of fuel energy",
                "frfossilfuel_heat": "Fraction of heating energy from fossil fuels",
                "frfossilfuel_nonheat": "Fraction of non-heating energy from fossil fuels",
            }

            missing_params = check_missing_params(
                critical_params,
                site.properties.anthropogenic_emissions.co2,
                "CO2 emission",
                "model accuracy",
            )

            for param, desc in critical_params.items():
                if param in missing_params:
                    annotator.add_issue(
                        path=f"sites[{site_index}]/properties/anthropogenic_emissions/co2",
                        param=param,
                        message=f"Missing {desc}",
                        fix=f"Add {param} value for CO2 emission calculations",
                        level="WARNING",
                    )

        # Check land cover
        if hasattr(site.properties, "land_cover") and site.properties.land_cover:
            self._collect_land_cover_issues(
                site.properties.land_cover, site_name, site_index, annotator
            )

    def _collect_land_cover_issues(
        self, land_cover, site_name: str, site_index: int, annotator: YAMLAnnotator
    ) -> None:
        """Collect land cover validation issues."""
        surface_types = ["bldgs", "grass", "dectr", "evetr", "bsoil", "paved", "water"]

        for surface_type in surface_types:
            if hasattr(land_cover, surface_type):
                surface = getattr(land_cover, surface_type)
                if surface:
                    # Get surface fraction
                    sfr_value = 0
                    if hasattr(surface, "sfr") and surface.sfr is not None:
                        sfr_value = getattr(surface.sfr, "value", surface.sfr)

                    if sfr_value > 0:
                        path = (
                            f"sites[{site_index}]/properties/land_cover/{surface_type}"
                        )

                        # Building-specific checks
                        if surface_type == "bldgs" and sfr_value > 0.05:
                            if not hasattr(surface, "bldgh") or surface.bldgh is None:
                                annotator.add_issue(
                                    path=path,
                                    param="bldgh",
                                    message=f"Building height required (fraction: {sfr_value:.1%})",
                                    fix="Add building height in meters (e.g., 10-50m for urban areas)",
                                    level="WARNING",
                                )

                            if (
                                not hasattr(surface, "faibldg")
                                or surface.faibldg is None
                            ):
                                annotator.add_issue(
                                    path=path,
                                    param="faibldg",
                                    message="Frontal area index needed for wind calculations",
                                    fix="Add frontal area index (typical: 0.1-0.7)",
                                    level="WARNING",
                                )

                        # Thermal layers check
                        if (
                            hasattr(surface, "thermal_layers")
                            and surface.thermal_layers
                        ):
                            thermal = surface.thermal_layers

                            # First check if the raw YAML contains 'cp' instead of 'rho_cp'
                            yaml_path = getattr(self, "_yaml_path", None)
                            if yaml_path and self._check_raw_yaml_for_cp_field(
                                yaml_path, path
                            ):
                                annotator.add_issue(
                                    path=f"{path}/thermal_layers",
                                    param="cp_field",
                                    message="Found 'cp' field - should be 'rho_cp'",
                                    fix="Change 'cp:' to 'rho_cp:' in your YAML file",
                                    level="WARNING",
                                )
                                # This is a naming issue, not a missing parameter issue
                                if self._check_thermal_layers_naming_issue(
                                    surface.thermal_layers, surface_type, site_name
                                ):
                                    has_issues = True
                            elif (
                                not _is_valid_layer_array(getattr(thermal, "dz", None))
                                or not _is_valid_layer_array(
                                    getattr(thermal, "k", None)
                                )
                                or not _is_valid_layer_array(
                                    getattr(thermal, "rho_cp", None)
                                )
                            ):
                                annotator.add_issue(
                                    path=f"{path}/thermal_layers",
                                    param="thermal_layers",
                                    message="Incomplete thermal layer properties",
                                    fix="Add dz (thickness), k (conductivity), and rho_cp (heat capacity) arrays",
                                    level="WARNING",
                                )
                                # Add to validation summary for missing parameters
                                self._validation_summary["total_warnings"] += 1
                                self._validation_summary["issue_types"].add(
                                    "Missing thermal layer parameters"
                                )
                                if (
                                    site_name
                                    not in self._validation_summary["sites_with_issues"]
                                ):
                                    self._validation_summary[
                                        "sites_with_issues"
                                    ].append(site_name)
                                has_issues = True

                        # LAI range check for vegetation surfaces
                        if (
                            surface_type in ["grass", "dectr", "evetr"]
                            and hasattr(surface, "lai")
                            and surface.lai
                        ):
                            lai = surface.lai

                            # Check laimin vs laimax
                            if lai.laimin is not None and lai.laimax is not None:
                                laimin_val = (
                                    lai.laimin.value
                                    if hasattr(lai.laimin, "value")
                                    else lai.laimin
                                )
                                laimax_val = (
                                    lai.laimax.value
                                    if hasattr(lai.laimax, "value")
                                    else lai.laimax
                                )

                                if laimin_val > laimax_val:
                                    annotator.add_issue(
                                        path=f"{path}/lai",
                                        param="laimin_laimax",
                                        message=f"LAI range invalid: laimin ({laimin_val}) > laimax ({laimax_val})",
                                        fix="Set laimin <= laimax (typical values: laimin=0.1-1.0, laimax=3.0-8.0)",
                                        level="WARNING",
                                    )

                            # Check baset vs gddfull
                            if lai.baset is not None and lai.gddfull is not None:
                                baset_val = (
                                    lai.baset.value
                                    if hasattr(lai.baset, "value")
                                    else lai.baset
                                )
                                gddfull_val = (
                                    lai.gddfull.value
                                    if hasattr(lai.gddfull, "value")
                                    else lai.gddfull
                                )

                                if baset_val > gddfull_val:
                                    annotator.add_issue(
                                        path=f"{path}/lai",
                                        param="baset_gddfull",
                                        message=f"GDD range invalid: baset ({baset_val}) > gddfull ({gddfull_val})",
                                        fix="Set baset <= gddfull (typical values: baset=5-10 C, gddfull=200-1000 C.day)",
                                        level="WARNING",
                                    )

                        # Check vegetation parameters for biogenic CO2 calculations
                        if (
                            surface_type in ["grass", "dectr", "evetr"]
                            and sfr_value > 0
                        ):
                            from ..validation.core.utils import check_missing_params

                            vegetation_params = {
                                "beta_bioco2": "Biogenic CO2 exchange coefficient",
                                "alpha_bioco2": "Biogenic CO2 exchange coefficient",
                                "resp_a": "Respiration coefficient",
                                "resp_b": "Respiration coefficient",
                            }

                            missing_params = check_missing_params(
                                vegetation_params,
                                surface,
                                "vegetation",
                                "CO2 flux calculations",
                            )

                            for param, desc in vegetation_params.items():
                                param_with_desc = f"{param} ({desc})"
                                if param_with_desc in missing_params:
                                    annotator.add_issue(
                                        path=path,
                                        param=param,
                                        message=f"Missing {desc}",
                                        fix=f"Add {param} value for accurate CO2 flux calculations",
                                        level="WARNING",
                                    )

        # Check land cover fractions sum to 1.0
        surface_types = ["bldgs", "grass", "dectr", "evetr", "bsoil", "paved", "water"]
        fractions = {}

        for surface_type in surface_types:
            if hasattr(land_cover, surface_type):
                surface = getattr(land_cover, surface_type)
                if surface and hasattr(surface, "sfr") and surface.sfr is not None:
                    sfr_value = getattr(surface.sfr, "value", surface.sfr)
                    fractions[surface_type] = (
                        float(sfr_value) if sfr_value is not None else 0.0
                    )
                else:
                    fractions[surface_type] = 0.0
            else:
                fractions[surface_type] = 0.0

        total_fraction = sum(fractions.values())
        tolerance = 1e-6

        if abs(total_fraction - 1.0) > tolerance:
            fraction_details = ", ".join([f"{k}={v:.3f}" for k, v in fractions.items()])
            difference = abs(total_fraction - 1.0)
            annotator.add_issue(
                path=f"sites[{site_index}]/properties/land_cover",
                param="surface_fractions",
                message=f"Land cover fractions must sum to 1.0 within tolerance {tolerance} (got {total_fraction:.6f}, difference {difference:.2e}): {fraction_details}",
                fix=f"Adjust surface fractions so they sum to 1.0 within tolerance {tolerance}",
                level="WARNING",
            )

    # @model_validator(mode="after")
    # def check_forcing(self):
    #     from .._load import load_SUEWS_Forcing_met_df_yaml
    #     forcing = load_SUEWS_Forcing_met_df_yaml(self.model.control.forcing_file.value)
    #
    #     # Cut the forcing data to model period
    #     cut_forcing = forcing.loc[self.model.control.start_time: self.model.control.end_time]
    #
    #     # Check for missing forcing data
    #     missing_data = any(cut_forcing.isna().any())
    #     if missing_data:
    #         raise ValueError("Forcing data contains missing values.")
    #
    #     # Check initial meteorology (for initial_states)
    #     first_day_forcing = cut_forcing.loc[self.model.control.start_time]
    #     first_day_min_temp = first_day_forcing.iloc[0]["Tair"]
    #     first_day_precip = first_day_forcing.iloc[0]["rain"] # Could check previous day if available
    #
    #     # Use min temp for surface temperature states
    #     for site in self.site:
    #         for surf_type in SurfaceType:
    #             surface = getattr(site.initial_states, surf_type)
    #             surface.temperature.value = [first_day_min_temp]*5
    #             surface.tsfc.value = first_day_min_temp
    #             surface.tin.value = first_day_min_temp
    #
    #     # Use precip to determine wetness state
    #     for site in self.site:
    #         for surf_type in SurfaceType:
    #             surface_is = getattr(site.initial_states, surf_type)
    #             surface_props =getattr(site.properties.land_cover, surf_type)
    #             if first_day_precip:
    #                 surface_is.state.value = surface_props.statelimit
    #                 surface_is.soilstore.value = surface_props.soilstorecap
    #                 if first_day_min_temp < 4:
    #                     surface_is.snowpack.value = surface_props.snowpacklimit
    #                     surface_is.snowfrac.value = 0.5 # Can these sum to greater than 1?
    #                     surface_is.icefrac.value = 0.5 # Can these sum to greater than 1?
    #                     surface_is.snowwater.value = 1 # TODO: What is the limit to this?
    #                     surface_is.snowdens.value = surface_props.snowdensmax
    #             else:
    #                 surface_is.state.value = 0
    #     return self

    @model_validator(mode="after")
    def validate_building_layers(self) -> "SUEWSConfig":
        """Validate building layer consistency across all sites.

        Checks that building-related arrays have consistent lengths:
        - Building heights array must have nlayer+1 elements
        - Building fractions array must have nlayer elements
        - Building scales array must have nlayer elements
        - Roof layers count must match nlayer
        - Wall layers count must match nlayer
        """
        from .type import RefValue  # Import here to avoid circular import

        for site_index, site in enumerate(self.sites):
            # Get site name (Site class has name field with default "test site")
            site_name = getattr(site, "name", f"Site {site_index + 1}")

            # Get vertical layers (building validation is on vertical layers, not bldgs)
            if not site.properties or not site.properties.vertical_layers:
                continue

            vertical_layers = site.properties.vertical_layers

            # Extract nlayer value using helper for consistent unwrapping
            nlayer_val = _unwrap_value(vertical_layers.nlayer)

            # Validate building heights array
            if (
                hasattr(vertical_layers, "height")
                and vertical_layers.height is not None
            ):
                heights_val = _unwrap_value(vertical_layers.height)
                expected_height_len = nlayer_val + 1
                if len(heights_val) != expected_height_len:
                    raise ValueError(
                        f"{site_name}: Building heights array length ({len(heights_val)}) "
                        f"must be nlayer+1 ({expected_height_len})"
                    )

            # Validate building fractions array
            if (
                hasattr(vertical_layers, "building_frac")
                and vertical_layers.building_frac is not None
            ):
                fractions_val = _unwrap_value(vertical_layers.building_frac)
                if len(fractions_val) != nlayer_val:
                    raise ValueError(
                        f"{site_name}: Building fractions array length ({len(fractions_val)}) "
                        f"must match nlayer ({nlayer_val})"
                    )

            # Validate building scales array
            if (
                hasattr(vertical_layers, "building_scale")
                and vertical_layers.building_scale is not None
            ):
                scales_val = (
                    vertical_layers.building_scale.value
                    if isinstance(vertical_layers.building_scale, RefValue)
                    else vertical_layers.building_scale
                )
                if len(scales_val) != nlayer_val:
                    raise ValueError(
                        f"{site_name}: Building scales array length ({len(scales_val)}) "
                        f"must match nlayer ({nlayer_val})"
                    )

            # Validate roof layers count
            if hasattr(vertical_layers, "roofs") and vertical_layers.roofs is not None:
                if len(vertical_layers.roofs) != nlayer_val:
                    raise ValueError(
                        f"{site_name}: Roof layers count ({len(vertical_layers.roofs)}) "
                        f"must match nlayer ({nlayer_val})"
                    )

            # Validate wall layers count
            if hasattr(vertical_layers, "walls") and vertical_layers.walls is not None:
                if len(vertical_layers.walls) != nlayer_val:
                    raise ValueError(
                        f"{site_name}: Wall layers count ({len(vertical_layers.walls)}) "
                        f"must match nlayer ({nlayer_val})"
                    )

        return self

    @model_validator(mode="after")
    def validate_surface_states(self) -> "SUEWSConfig":
        """Validate surface state types match expected surface types across all sites.

        Ensures that initial states have appropriate surface types:
        - InitialStateVeg: DECTR, EVETR, or GRASS
        - InitialStateDectr: DECTR only
        - All surface-specific initial state classes have correct surface types
        """
        from .type import SurfaceType  # Import here to avoid circular import

        for site_index, site in enumerate(self.sites):
            # Get site name (Site class has name field with default "test site")
            site_name = getattr(site, "name", f"Site {site_index + 1}")

            # Get initial states
            if not site.initial_states:
                continue

            initial_states = site.initial_states

            # Validate vegetated surface states (evetr, dectr, grass)
            vegetated_surfaces = ["evetr", "dectr", "grass"]
            for surface_name in vegetated_surfaces:
                if hasattr(initial_states, surface_name):
                    surface_state = getattr(initial_states, surface_name)
                    if surface_state and hasattr(surface_state, "_surface_type"):
                        surface_type = surface_state._surface_type
                        expected_types = [
                            SurfaceType.DECTR,
                            SurfaceType.EVETR,
                            SurfaceType.GRASS,
                        ]

                        # For vegetated surfaces, check they're in valid vegetated types
                        if (
                            surface_name in ["evetr", "grass"]
                            and surface_type not in expected_types
                        ):
                            raise ValueError(
                                f"{site_name}: Invalid surface type {surface_type} for vegetated surface {surface_name}"
                            )

                        # For deciduous trees, check it's specifically DECTR
                        if (
                            surface_name == "dectr"
                            and surface_type != SurfaceType.DECTR
                        ):
                            raise ValueError(
                                f"{site_name}: {surface_name} state is only valid for deciduous trees, got {surface_type}"
                            )

        return self

    @model_validator(mode="before")
    @classmethod
    def convert_legacy_hdd_formats(cls, data):
        """Convert legacy HDD_ID list formats across all sites.

        This handles backward compatibility for HDD_ID data that may be provided
        as lists instead of dictionaries. Migrated from InitialStates class
        to ensure consistent handling across all sites in configuration.
        """
        if isinstance(data, dict) and "sites" in data:
            sites = data["sites"]
            if isinstance(sites, list):
                for site in sites:
                    if isinstance(site, dict) and "initial_states" in site:
                        initial_states = site["initial_states"]
                        if (
                            isinstance(initial_states, dict)
                            and "hdd_id" in initial_states
                        ):
                            hdd_value = initial_states["hdd_id"]
                            if isinstance(hdd_value, list):
                                # Convert from legacy list format to HDD_ID object
                                if len(hdd_value) >= 12:
                                    initial_states["hdd_id"] = {
                                        "hdd_accum": hdd_value[0],
                                        "cdd_accum": hdd_value[1],
                                        "temp_accum": hdd_value[2],
                                        "temp_5day_accum": hdd_value[3],
                                        "precip_accum": hdd_value[4],
                                        "days_since_rain_accum": hdd_value[5],
                                        "hdd_daily": hdd_value[6],
                                        "cdd_daily": hdd_value[7],
                                        "temp_daily_mean": hdd_value[8],
                                        "temp_5day_mean": hdd_value[9],
                                        "precip_daily_total": hdd_value[10],
                                        "days_since_rain": hdd_value[11],
                                    }
                                else:
                                    # If list is too short, create default HDD_ID
                                    initial_states["hdd_id"] = {}
        return data

    @model_validator(mode="after")
    def set_surface_types_validation(self) -> "SUEWSConfig":
        """Set surface types on all land cover properties across all sites.

        This validator ensures that all surface property objects have their
        surface type identifiers properly set. This is required for internal
        validation and processing logic. Migrated from LandCover.set_surface_types
        to provide centralized validation across all sites.
        """
        from .type import SurfaceType  # Import here to avoid circular import

        # Surface type mapping
        surface_map = {
            "paved": SurfaceType.PAVED,
            "bldgs": SurfaceType.BLDGS,
            "dectr": SurfaceType.DECTR,
            "evetr": SurfaceType.EVETR,
            "grass": SurfaceType.GRASS,
            "bsoil": SurfaceType.BSOIL,
            "water": SurfaceType.WATER,
        }

        for site_index, site in enumerate(self.sites):
            if site.properties and site.properties.land_cover:
                land_cover = site.properties.land_cover

                # Set surface types for each surface property
                for surface_name, surface_type in surface_map.items():
                    if hasattr(land_cover, surface_name):
                        surface_prop = getattr(land_cover, surface_name)
                        if surface_prop and hasattr(surface_prop, "set_surface_type"):
                            try:
                                surface_prop.set_surface_type(surface_type)
                            except Exception as e:
                                # Log the error but continue processing other surfaces
                                site_name = getattr(site, "name", f"Site {site_index}")
                                import warnings

                                warnings.warn(
                                    f"{site_name}: Failed to set surface type for {surface_name}: {str(e)}",
                                    UserWarning,
                                    stacklevel=2,
                                )

        return self

    @model_validator(mode="after")
    def validate_hourly_profile_hours(self) -> "SUEWSConfig":
        """Validate hourly profiles have complete and valid hour coverage.

        Ensures all HourlyProfile instances across all sites have:
        - All hour keys between 1 and 24 (inclusive)
        - Exactly hours 1-24 with no missing hours or duplicates

        This applies to profiles like snow, irrigation, anthropogenic heat,
        population, traffic, and human activity profiles.
        Migrated from HourlyProfile.validate_hours for centralized validation.
        """
        for site_index, site in enumerate(self.sites):
            # Get site name (Site class has name field with default "test site")
            site_name = getattr(site, "name", f"Site {site_index + 1}")
            errors = []

            # Collect all HourlyProfile instances from this site
            hourly_profiles = []

            # Snow profiles
            if site.properties and site.properties.snow:
                hourly_profiles.append((
                    "snow.snowprof_24hr",
                    site.properties.snow.snowprof_24hr,
                ))

            # Irrigation profiles
            if site.properties and site.properties.irrigation:
                irrigation = site.properties.irrigation
                hourly_profiles.extend([
                    ("irrigation.wuprofa_24hr", irrigation.wuprofa_24hr),
                    ("irrigation.wuprofm_24hr", irrigation.wuprofm_24hr),
                ])

            # Anthropogenic emissions profiles (heat)
            if site.properties and site.properties.anthropogenic_emissions:
                anthro_heat = site.properties.anthropogenic_emissions.heat
                hourly_profiles.extend([
                    (
                        "anthropogenic_emissions.heat.ahprof_24hr",
                        anthro_heat.ahprof_24hr,
                    ),
                    (
                        "anthropogenic_emissions.heat.popprof_24hr",
                        anthro_heat.popprof_24hr,
                    ),
                ])

                # CO2 profiles (traffic and human activity)
                anthro_co2 = site.properties.anthropogenic_emissions.co2
                hourly_profiles.extend([
                    (
                        "anthropogenic_emissions.co2.traffprof_24hr",
                        anthro_co2.traffprof_24hr,
                    ),
                    (
                        "anthropogenic_emissions.co2.humactivity_24hr",
                        anthro_co2.humactivity_24hr,
                    ),
                ])

            # Validate each profile
            for profile_name, profile in hourly_profiles:
                if profile is None:
                    continue

                # Validate both working_day and holiday profiles
                for day_type in ["working_day", "holiday"]:
                    day_profile = getattr(profile, day_type, None)
                    if day_profile is None:
                        continue

                    # Check hour keys can be converted to integers and are in valid range
                    try:
                        hours = [int(h) for h in day_profile.keys()]
                    except (ValueError, TypeError):
                        errors.append(
                            f"{site_name}: {profile_name}.{day_type} has invalid hour keys. "
                            f"Hour keys must be convertible to integers."
                        )
                        continue

                    # Check hour range (1-24)
                    if not all(1 <= h <= 24 for h in hours):
                        errors.append(
                            f"{site_name}: {profile_name}.{day_type} has hour values outside range 1-24. "
                            f"Found hours: {sorted(hours)}"
                        )

                    # Check complete coverage (must have hours 1-24)
                    if sorted(hours) != list(range(1, 25)):
                        missing_hours = set(range(1, 25)) - set(hours)
                        extra_hours = set(hours) - set(range(1, 25))
                        error_parts = []
                        if missing_hours:
                            error_parts.append(
                                f"missing hours: {sorted(missing_hours)}"
                            )
                        if extra_hours:
                            error_parts.append(f"extra hours: {sorted(extra_hours)}")

                        errors.append(
                            f"{site_name}: {profile_name}.{day_type} must have all hours from 1 to 24. "
                            f"Issues: {', '.join(error_parts)}"
                        )

            if errors:
                raise ValueError("\n".join(errors))

        return self

    @model_validator(mode="after")
    def validate_dls_parameters(self) -> "SUEWSConfig":
        """Validate daylight saving time parameters across all sites.

        Performs validation checks:
        1. Consistency: both startdls and enddls set, or both None (ERROR)
        2. Leap year refinement: DOY 366 only valid in leap years (ERROR)
        3. Compare user values with calculated DLS: Informs if values differ from location-based calculations (INFO)

        These validations are particularly useful when Phase C runs standalone
        or when loading YAML directly via SUEWSConfig.from_yaml().
        """
        # Initialize validation summary if not already present
        if not hasattr(self, "_validation_summary"):
            self._validation_summary = {
                "total_warnings": 0,
                "sites_with_issues": [],
                "issue_types": set(),
                "yaml_path": getattr(self, "_yaml_path", None),
                "detailed_messages": [],
                "info_messages": [],
            }

        # Get simulation year from model.control.start_time
        try:
            year = int(str(self.model.control.start_time)[:4])
        except (AttributeError, ValueError, IndexError):
            year = None  # Cannot determine year, skip leap year check

        is_leap = calendar.isleap(year) if year else None
        max_doy = 366 if (is_leap or year is None) else 365

        errors = []

        for site_index, site in enumerate(self.sites):
            # Get site name (Site class has name field with default "test site")
            site_name = getattr(site, "name", f"Site {site_index + 1}")

            if not (site.properties and site.properties.anthropogenic_emissions):
                continue

            anthro = site.properties.anthropogenic_emissions

            # Extract values (handle RefValue wrapper)
            startdls_val = (
                anthro.startdls.value
                if hasattr(anthro.startdls, "value")
                else anthro.startdls
            )
            enddls_val = (
                anthro.enddls.value
                if hasattr(anthro.enddls, "value")
                else anthro.enddls
            )

            # 1. Consistency check: both set or both None
            if (startdls_val is None) != (enddls_val is None):
                errors.append(
                    f"{site_name}: startdls and enddls must both be set or both be None. "
                    "Cannot have only one parameter set."
                )
                continue  # Skip other checks if inconsistent

            # If both None, skip remaining checks
            if startdls_val is None and enddls_val is None:
                continue

            # 2. Leap year refinement
            if year:
                if startdls_val > max_doy:
                    errors.append(
                        f"{site_name}: startdls DOY {int(startdls_val)} invalid for "
                        f"{'leap' if is_leap else 'non-leap'} year {year}. "
                        f"Must be in range [1, {max_doy}]"
                    )

                if enddls_val > max_doy:
                    errors.append(
                        f"{site_name}: enddls DOY {int(enddls_val)} invalid for "
                        f"{'leap' if is_leap else 'non-leap'} year {year}. "
                        f"Must be in range [1, {max_doy}]"
                    )

            # 3. Compare user values with calculated DLS values (informational only)
            # Get latitude and longitude for DLS calculation
            try:
                lat_val = (
                    site.properties.lat.value
                    if hasattr(site.properties.lat, "value")
                    else site.properties.lat
                )
                lng_val = (
                    site.properties.lng.value
                    if hasattr(site.properties.lng, "value")
                    else site.properties.lng
                )

                if lat_val is not None and lng_val is not None and year:
                    # Import DLSCheck dynamically to avoid circular imports
                    from ..validation.core.yaml_helpers import DLSCheck

                    # Calculate what DLS values should be
                    dls = DLSCheck(lat=lat_val, lng=lng_val, year=year)
                    calculated_start, calculated_end, _ = dls.compute_dst_transitions()

                    if calculated_start and calculated_end:
                        # Compare user values with calculated values
                        # Create separate messages for each parameter

                        if calculated_start != startdls_val:
                            info_msg = (
                                f"startdls for site {site_name}: DLS values differ from calculated "
                                f"values based on your location (lat={lat_val:.2f}, lng={lng_val:.2f}). "
                                f"Check your value ({int(startdls_val)}) against the calculated one "
                                f"({int(calculated_start)}). You might need to change your startdls."
                            )
                            self._validation_summary["detailed_messages"].append(
                                info_msg
                            )
                            self._validation_summary["info_messages"].append(info_msg)

                        if calculated_end != enddls_val:
                            info_msg = (
                                f"enddls for site {site_name}: DLS values differ from calculated "
                                f"values based on your location (lat={lat_val:.2f}, lng={lng_val:.2f}). "
                                f"Check your value ({int(enddls_val)}) against the calculated one "
                                f"({int(calculated_end)}). You might need to change your enddls."
                            )
                            self._validation_summary["detailed_messages"].append(
                                info_msg
                            )
                            self._validation_summary["info_messages"].append(info_msg)
                elif lat_val is not None and lng_val is not None:
                    info_msg = (
                        f"{site_name}: Cannot compare DLS values because simulation year "
                        f"is not specified. Consider setting model.control.start_time."
                    )
                    self._validation_summary["info_messages"].append(info_msg)

            except (AttributeError, TypeError, ImportError):
                # Cannot calculate DLS, skip comparison
                pass

        # Raise errors if any
        if errors:
            raise ValueError("\n".join(errors))

        return self

    @classmethod
    def _transform_validation_error(
        cls, error: ValidationError, config_data: dict
    ) -> ValidationError:
        """Transform Pydantic validation errors to use GRIDID instead of array indices.

        Uses structured error data to avoid string replacement collisions when
        GRIDID values overlap with array indices (e.g., site 0 has GRIDID=1).
        """

        # Extract GRIDID mapping from sites
        sites = config_data.get("sites", [])
        site_gridid_map = {}
        for idx, site in enumerate(sites):
            if isinstance(site, dict):
                gridiv = site.get("gridiv")
                if isinstance(gridiv, dict) and "value" in gridiv:
                    site_gridid_map[idx] = gridiv["value"]
                elif gridiv is not None:
                    site_gridid_map[idx] = gridiv
                else:
                    site_gridid_map[idx] = idx  # Fallback to index
            else:
                site_gridid_map[idx] = idx  # Fallback to index

        # Process structured errors (not string manipulation!)
        modified_errors = []
        for err in error.errors():
            err_copy = err.copy()
            loc_list = list(err_copy["loc"])

            # Replace numeric site index with GRIDID in location tuple
            if (
                len(loc_list) >= 2
                and loc_list[0] == "sites"
                and isinstance(loc_list[1], int)
            ):
                site_idx = loc_list[1]
                if site_idx in site_gridid_map:
                    loc_list[1] = site_gridid_map[site_idx]

            err_copy["loc"] = tuple(loc_list)
            modified_errors.append(err_copy)

        # Format into readable message
        error_lines = [
            f"{error.error_count()} validation error{'s' if error.error_count() > 1 else ''} for SUEWSConfig"
        ]

        for err in modified_errors:
            loc_str = ".".join(str(x) for x in err["loc"])
            error_lines.append(loc_str)
            error_lines.append(
                f"  {err['msg']} [type={err['type']}]"
            )
            if "url" in err:
                error_lines.append(f"    For further information visit {err['url']}")

        error_msg = "\n".join(error_lines)
        raise ValueError(f"SUEWS Configuration Validation Error:\n{error_msg}")

    @classmethod
    def from_yaml(
        cls,
        path: str,
        use_conditional_validation: bool = True,
        strict: bool = True,
        auto_generate_annotated: bool = False,
    ) -> "SUEWSConfig":
        """Initialize SUEWSConfig from YAML file with conditional validation.

        Args:
            path (str): Path to YAML configuration file
            use_conditional_validation (bool): Whether to use conditional validation
            strict (bool): If True, raise errors on validation failure
            auto_generate_annotated (bool): If True, automatically generate annotated YAML when validation issues found

        Returns:
            SUEWSConfig: Instance of SUEWSConfig initialized from YAML
        """
        with open(path, "r") as file:
            config_data = yaml.load(file, Loader=yaml.FullLoader)

        # Store yaml path in config data for later use
        config_data["_yaml_path"] = path
        config_data["_auto_generate_annotated"] = auto_generate_annotated

        # Log schema version information if present
        from ..schema import CURRENT_SCHEMA_VERSION, get_schema_compatibility_message

        if "schema_version" in config_data:
            logger_supy.info(
                f"Loading config with schema version: {config_data['schema_version']}"
            )
            # Check compatibility and log any concerns
            message = get_schema_compatibility_message(config_data["schema_version"])
            if message:
                logger_supy.info(message)
        else:
            logger_supy.debug(
                f"No schema version specified, assuming current ({CURRENT_SCHEMA_VERSION})"
            )
            # Set default schema version
            config_data["schema_version"] = CURRENT_SCHEMA_VERSION

        if use_conditional_validation:
            logger_supy.debug(
                "Running comprehensive Pydantic validation with conditional checks."
            )
            try:
                return cls(**config_data)
            except ValidationError as e:
                # Transform Pydantic validation error messages to use GRIDID instead of array indices
                transformed_error = cls._transform_validation_error(e, config_data)
                raise transformed_error
        else:
            logger_supy.info("Validation disabled by user. Loading without checks.")
            return cls.model_construct(**config_data)

    def create_multi_index_columns(self, columns_file: str) -> pd.MultiIndex:
        """Create MultiIndex from df_state_columns.txt"""
        with open(columns_file, "r") as f:
            lines = f.readlines()

        tuples = []
        for line in lines:
            col_name, indices = line.strip().split(",", 1)
            str_indices = f"{indices}" if indices != "0" else "0"
            tuples.append((col_name, str_indices))

        return pd.MultiIndex.from_tuples(tuples)

    def to_df_state(
        self, use_conditional_validation: bool = False, strict: bool = False
    ) -> pd.DataFrame:
        """Convert config to DataFrame state format with optional conditional validation.

        Args:
            use_conditional_validation (bool): Whether to run conditional validation before conversion.
                Defaults to False since validation module is not loaded by default.
            strict (bool): If True, fail on validation errors; if False, warn and continue

        Returns:
            pd.DataFrame: DataFrame containing SUEWS configuration state
        """
        if use_conditional_validation and _validation_available:
            # Pre-validate configuration before conversion
            config_data = self.model_dump()
            try:
                enhanced_to_df_state_validation(config_data, strict=strict)
            except ValueError:
                if strict:
                    raise
                # Continue with warnings already issued
        elif use_conditional_validation and not _validation_available:
            warnings.warn(
                "Conditional validation requested but validation module not available. "
                "Proceeding without additional validation checks.",
                ConditionalValidationWarning,
                stacklevel=2,
            )

        # Proceed with DataFrame conversion
        try:
            list_df_site = []
            for i in range(len(self.sites)):
                grid_id = self.sites[i].gridiv
                df_site = self.sites[i].to_df_state(grid_id)
                df_model = self.model.to_df_state(grid_id)
                df_site = pd.concat([df_site, df_model], axis=1)
                # Remove duplicate columns immediately after combining site+model
                # This prevents InvalidIndexError when concatenating multiple sites (axis=0)
                df_site = df_site.loc[:, ~df_site.columns.duplicated()]
                list_df_site.append(df_site)

            df = pd.concat(list_df_site, axis=0)

            # Add metadata columns using batch-concat pattern to avoid fragmentation warning
            metadata_df = pd.DataFrame(
                {
                    ("config", "0"): self.name,
                    ("description", "0"): self.description,
                },
                index=df.index,
            )
            df = pd.concat([df, metadata_df], axis=1)
        except Exception as e:
            if use_conditional_validation and not strict:
                warnings.warn(
                    f"Error during to_df_state conversion: {e}. This may be due to invalid parameters for disabled methods."
                )
                raise
            else:
                raise

        # # Fix level=1 columns sorted alphabetically not numerically (i.e. 10 < 2)
        # # Filter columns based on level=0 criteria
        # level_0_counts = df.columns.get_level_values(0).value_counts()
        # columns_to_sort = [col for col in df.columns if level_0_counts[col[0]] >= 10]

        # # Sort the filtered columns numericallyÃ­
        # def sort_key(col):
        #     try:
        #         return (col[0], ast.literal_eval(col[1]))
        #     except ValueError:
        #         return (col[0], col[1])

        # sorted_columns = sorted(columns_to_sort, key=sort_key)

        # # Combine the sorted columns with the remaining columns
        # remaining_columns = [col for col in df.columns if col not in columns_to_sort]
        # final_columns = remaining_columns + sorted_columns

        # # Reindex the DataFrame using the final column order
        # df = df.reindex(columns=pd.MultiIndex.from_tuples(final_columns))

        # # set index name
        # df.index.set_names("grid", inplace=True)

        # Custom sorting function for level=1 columns
        def parse_level_1(value):
            """Parse level=1 column values into sortable tuples."""
            if value.startswith("(") and value.endswith(")"):
                # Remove parentheses and split by comma
                parts = value[1:-1].split(",")
                # Convert to integers, ignoring empty strings
                return tuple(int(part) for part in parts if part)
            try:
                # Try converting to an integer for single values like "x"
                return (int(value),)
            except ValueError:
                # Fallback for non-numeric values
                return (value,)

        # Extract MultiIndex levels as a list of tuples
        columns = list(df.columns)

        # Sort the columns using the custom function
        sorted_columns = sorted(
            columns, key=lambda col: (col[0], parse_level_1(col[1]))
        )

        # Re-create the MultiIndex with the sorted columns
        sorted_multi_index = pd.MultiIndex.from_tuples(sorted_columns)

        # Reindex the DataFrame with the sorted MultiIndex to preserve values
        df = df.reindex(columns=sorted_multi_index)

        # set column names
        df.columns.set_names(["var", "ind_dim"], inplace=True)
        df.index.name = "grid"



        return df

    @classmethod
    def from_df_state(cls, df: pd.DataFrame) -> "SUEWSConfig":
        """Create config from DataFrame state format.

        Args:
            df (pd.DataFrame): DataFrame containing SUEWS configuration state.

        Returns:
            SUEWSConfig: Instance of SUEWSConfig reconstructed from DataFrame.
        """
        # Initialize with default values
        config = cls()

        # Get grid IDs from DataFrame index
        grid_ids = df.index.tolist()

        # Create list of sites
        sites = []
        for grid_id in grid_ids:
            # Create site instance
            site = Site(gridiv=grid_id)

            # Set site properties
            site_properties = SiteProperties.from_df_state(df, grid_id)
            site.properties = site_properties

            # Set initial states
            initial_states = InitialStates.from_df_state(df, grid_id)
            site.initial_states = initial_states

            sites.append(site)

        # Update config with reconstructed data
        config.sites = sites

        # Reconstruct model
        config.model = Model.from_df_state(df, grid_ids[0])

        # Set name and description, using defaults if columns don't exist
        if ("config", "0") in df.columns:
            config.name = df.loc[grid_ids[0], ("config", "0")]
        elif "config" in df.columns:
            config.name = df["config"].iloc[0]
        else:
            config.name = "Converted from legacy format"

        if ("description", "0") in df.columns:
            config.description = df.loc[grid_ids[0], ("description", "0")]
        elif "description" in df.columns:
            config.description = df["description"].iloc[0]
        else:
            config.description = (
                "Configuration converted from legacy SUEWS table format"
            )

        return config

    def to_yaml(self, path: str = "./config-suews.yml"):
        """Convert config to YAML format"""
        # Use mode='json' to serialize enums as their values
        config_dict = self.model_dump(exclude_none=True, mode="json")
        with open(path, "w") as file:
            yaml.dump(
                config_dict,
                file,
                sort_keys=False,
                allow_unicode=True,
            )


def init_config_from_yaml(path: str = "./config-suews.yml") -> SUEWSConfig:
    """Initialize SUEWSConfig from YAML file.

    This is a convenience function that delegates to SUEWSConfig.from_yaml
    for consistency in version checking and validation.
    """
    return SUEWSConfig.from_yaml(path)
